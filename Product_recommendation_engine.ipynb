{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Product_recommendation_engine.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "SPUO-uA0210_",
        "Wity6s-929F4",
        "PE1d-VlkWL9t",
        "nSGbMCy23T21",
        "etfkssEUly3g",
        "MEbHHBGnyGCZ",
        "_9B0CdqEsEsv",
        "wEfnYp3EVG7r",
        "Zsyy0PTV4-ft",
        "apV0tNKP5JsU",
        "1m3t6bBg5OgR",
        "dxSKHKVimsSP",
        "eqGLNRxwmr5E"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtJVtCEyr9GV",
        "outputId": "0c865972-a68e-4968-c5f3-33686dd75831"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPUO-uA0210_"
      },
      "source": [
        "### Importing Libraries & HealthCheck"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeUnDCThQbqs"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fB9cIkdQQd3M"
      },
      "source": [
        "products = pd.read_csv('/content/gdrive/MyDrive/Colab Data/sample30.csv')"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q44RbjOfS7li",
        "outputId": "b59769e9-9737-4382-e08f-6d1ab8c12343"
      },
      "source": [
        "products.shape"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30000, 15)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "l_fXIL-WQjy7",
        "outputId": "80007b0a-d132-4d1f-db9a-fea175bd49e4"
      },
      "source": [
        "products.head()\n"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>brand</th>\n",
              "      <th>categories</th>\n",
              "      <th>manufacturer</th>\n",
              "      <th>name</th>\n",
              "      <th>reviews_date</th>\n",
              "      <th>reviews_didPurchase</th>\n",
              "      <th>reviews_doRecommend</th>\n",
              "      <th>reviews_rating</th>\n",
              "      <th>reviews_text</th>\n",
              "      <th>reviews_title</th>\n",
              "      <th>reviews_userCity</th>\n",
              "      <th>reviews_userProvince</th>\n",
              "      <th>reviews_username</th>\n",
              "      <th>user_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AV13O1A8GV-KLJ3akUyj</td>\n",
              "      <td>Universal Music</td>\n",
              "      <td>Movies, Music &amp; Books,Music,R&amp;b,Movies &amp; TV,Mo...</td>\n",
              "      <td>Universal Music Group / Cash Money</td>\n",
              "      <td>Pink Friday: Roman Reloaded Re-Up (w/dvd)</td>\n",
              "      <td>2012-11-30T06:21:45.000Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>i love this album. it's very good. more to the...</td>\n",
              "      <td>Just Awesome</td>\n",
              "      <td>Los Angeles</td>\n",
              "      <td>NaN</td>\n",
              "      <td>joshua</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AV14LG0R-jtxr-f38QfS</td>\n",
              "      <td>Lundberg</td>\n",
              "      <td>Food,Packaged Foods,Snacks,Crackers,Snacks, Co...</td>\n",
              "      <td>Lundberg</td>\n",
              "      <td>Lundberg Organic Cinnamon Toast Rice Cakes</td>\n",
              "      <td>2017-07-09T00:00:00.000Z</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>Good flavor. This review was collected as part...</td>\n",
              "      <td>Good</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>dorothy w</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AV14LG0R-jtxr-f38QfS</td>\n",
              "      <td>Lundberg</td>\n",
              "      <td>Food,Packaged Foods,Snacks,Crackers,Snacks, Co...</td>\n",
              "      <td>Lundberg</td>\n",
              "      <td>Lundberg Organic Cinnamon Toast Rice Cakes</td>\n",
              "      <td>2017-07-09T00:00:00.000Z</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>Good flavor.</td>\n",
              "      <td>Good</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>dorothy w</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AV16khLE-jtxr-f38VFn</td>\n",
              "      <td>K-Y</td>\n",
              "      <td>Personal Care,Medicine Cabinet,Lubricant/Sperm...</td>\n",
              "      <td>K-Y</td>\n",
              "      <td>K-Y Love Sensuality Pleasure Gel</td>\n",
              "      <td>2016-01-06T00:00:00.000Z</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>I read through the reviews on here before look...</td>\n",
              "      <td>Disappointed</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>rebecca</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AV16khLE-jtxr-f38VFn</td>\n",
              "      <td>K-Y</td>\n",
              "      <td>Personal Care,Medicine Cabinet,Lubricant/Sperm...</td>\n",
              "      <td>K-Y</td>\n",
              "      <td>K-Y Love Sensuality Pleasure Gel</td>\n",
              "      <td>2016-12-21T00:00:00.000Z</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>My husband bought this gel for us. The gel cau...</td>\n",
              "      <td>Irritation</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>walker557</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     id            brand  ... reviews_username user_sentiment\n",
              "0  AV13O1A8GV-KLJ3akUyj  Universal Music  ...           joshua       Positive\n",
              "1  AV14LG0R-jtxr-f38QfS         Lundberg  ...        dorothy w       Positive\n",
              "2  AV14LG0R-jtxr-f38QfS         Lundberg  ...        dorothy w       Positive\n",
              "3  AV16khLE-jtxr-f38VFn              K-Y  ...          rebecca       Negative\n",
              "4  AV16khLE-jtxr-f38VFn              K-Y  ...        walker557       Negative\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rI3jPmwlwEL"
      },
      "source": [
        "def checkNull(df):\n",
        "    null_count = df.isnull().sum().sort_values(ascending = False)\n",
        "    null_count_percentage = (df.isnull().sum()/len(df)*100).sort_values(ascending = False)\n",
        "    final = pd.concat([null_count,null_count_percentage], axis = 1, keys = ['Count', 'Percentage_of_count'])\n",
        "    return final[final['Count']>0]"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "2LN3SBA3l1l3",
        "outputId": "a889d94d-7cfb-4882-d8cb-e13b65784ca1"
      },
      "source": [
        "checkNull(products)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Count</th>\n",
              "      <th>Percentage_of_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>reviews_userProvince</th>\n",
              "      <td>29830</td>\n",
              "      <td>99.433333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>reviews_userCity</th>\n",
              "      <td>28071</td>\n",
              "      <td>93.570000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>reviews_didPurchase</th>\n",
              "      <td>14068</td>\n",
              "      <td>46.893333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>reviews_doRecommend</th>\n",
              "      <td>2570</td>\n",
              "      <td>8.566667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>reviews_title</th>\n",
              "      <td>190</td>\n",
              "      <td>0.633333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>manufacturer</th>\n",
              "      <td>141</td>\n",
              "      <td>0.470000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>reviews_username</th>\n",
              "      <td>63</td>\n",
              "      <td>0.210000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>reviews_date</th>\n",
              "      <td>46</td>\n",
              "      <td>0.153333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_sentiment</th>\n",
              "      <td>1</td>\n",
              "      <td>0.003333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      Count  Percentage_of_count\n",
              "reviews_userProvince  29830            99.433333\n",
              "reviews_userCity      28071            93.570000\n",
              "reviews_didPurchase   14068            46.893333\n",
              "reviews_doRecommend    2570             8.566667\n",
              "reviews_title           190             0.633333\n",
              "manufacturer            141             0.470000\n",
              "reviews_username         63             0.210000\n",
              "reviews_date             46             0.153333\n",
              "user_sentiment            1             0.003333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wity6s-929F4"
      },
      "source": [
        "### Task #1 - Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNDVaUycmg3o"
      },
      "source": [
        "#Dropping all the columns with more than 40% missing data\n",
        "products.drop(columns=['reviews_userProvince','reviews_userCity','reviews_didPurchase'],inplace=True)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wygl9fzWuL8B"
      },
      "source": [
        "##Renaming the columns\n",
        "products.rename(columns = {'id' : 'productId'},inplace=True)\n",
        "products.rename(columns = {'reviews_username' : 'userId'},inplace=True)\n",
        "products.rename(columns = {'reviews_rating' : 'rating'},inplace=True)"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZCQeSU03R9f",
        "outputId": "a65cee78-b2e5-4153-cba2-16c51b93b178"
      },
      "source": [
        "#Drop the rows which do not have values for username as username is one of the unique fields\n",
        "products = products[~(products['userId'].isnull())]\n",
        "products.userId.value_counts()"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "byamazon customer    41\n",
              "mike                 41\n",
              "chris                32\n",
              "lisa                 16\n",
              "rick                 15\n",
              "                     ..\n",
              "gradgal               1\n",
              "sue44                 1\n",
              "amanda78              1\n",
              "pechang               1\n",
              "customer1234          1\n",
              "Name: userId, Length: 24914, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prvVttW5ngX1"
      },
      "source": [
        "# the value byamazon customer seams to be a placeholder default and should be removed\n",
        "products = products[~(products['userId']=='byamazon customer')]"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfTpHoipoKJX",
        "outputId": "955e3e31-a286-44f1-9f82-7d67174d0ca1"
      },
      "source": [
        "# Since the username is a unique value as claimed, we will just check the same,\n",
        "# by checking the reviews give by different customers on the same product\n",
        "products['combine'] = products['productId']+products['userId']\n",
        "products['combine'].value_counts()"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AVpfPaoqLJeJML435Xk9mike                15\n",
              "AVpfPaoqLJeJML435Xk9chris                9\n",
              "AVpfPaoqLJeJML435Xk9movielover           7\n",
              "AVpfPaoqLJeJML435Xk9thomas               7\n",
              "AVpfPaoqLJeJML435Xk9matt                 6\n",
              "                                        ..\n",
              "AVpfPaoqLJeJML435Xk9jcjimmy              1\n",
              "AVpfJP1C1cnluZ0-e3Xysmith2127            1\n",
              "AVpfJP1C1cnluZ0-e3Xydel737               1\n",
              "AVpf3VOfilAPnD_xjpunsamantha02           1\n",
              "AVpf9pzn1cnluZ0-uNTMbyjohnnie walker     1\n",
              "Name: combine, Length: 27586, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfRxZE98oyt2"
      },
      "source": [
        "# We can see there are multiple mike,chris who have reviewed the same product, \n",
        "# which we would assume is the same customer and rated the product consistently\n",
        "# So we keep the first of all the reviews and drop the duplicates\n",
        "products.drop_duplicates(subset='combine',keep='first',inplace=True)\n",
        "products.drop(['combine'],axis=1,inplace=True)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3luXbFXDtKmS",
        "outputId": "3b5dee24-8094-41d9-ad71-060ff13ea45e"
      },
      "source": [
        "checkNull(products)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Count</th>\n",
              "      <th>Percentage_of_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>reviews_doRecommend</th>\n",
              "      <td>1997</td>\n",
              "      <td>7.239179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>reviews_title</th>\n",
              "      <td>185</td>\n",
              "      <td>0.670630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>manufacturer</th>\n",
              "      <td>140</td>\n",
              "      <td>0.507504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>reviews_date</th>\n",
              "      <td>40</td>\n",
              "      <td>0.145001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Count  Percentage_of_count\n",
              "reviews_doRecommend   1997             7.239179\n",
              "reviews_title          185             0.670630\n",
              "manufacturer           140             0.507504\n",
              "reviews_date            40             0.145001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diNGUk9VPHEz"
      },
      "source": [
        "## Sentitment Analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PE1d-VlkWL9t"
      },
      "source": [
        "### Task #2 -Text Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsEcDcrLPGk2"
      },
      "source": [
        "#Prepare the dataset for sentiment Analysis, which consists of reviews_title, reviews_text, user_sentiment\n",
        "productSentiment  = products[['reviews_title', 'reviews_text', 'user_sentiment']]"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "dIIf28q-SiHx",
        "outputId": "94e9c902-9057-4dd3-8651-053d5dd246bb"
      },
      "source": [
        "productSentiment.head()"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviews_title</th>\n",
              "      <th>reviews_text</th>\n",
              "      <th>user_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Just Awesome</td>\n",
              "      <td>i love this album. it's very good. more to the...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Good</td>\n",
              "      <td>Good flavor. This review was collected as part...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Disappointed</td>\n",
              "      <td>I read through the reviews on here before look...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Irritation</td>\n",
              "      <td>My husband bought this gel for us. The gel cau...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Not worth it</td>\n",
              "      <td>My boyfriend and I bought this to spice things...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  reviews_title  ... user_sentiment\n",
              "0  Just Awesome  ...       Positive\n",
              "1          Good  ...       Positive\n",
              "3  Disappointed  ...       Negative\n",
              "4    Irritation  ...       Negative\n",
              "5  Not worth it  ...       Negative\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H601uLEncCOG"
      },
      "source": [
        "def concatTitleText(title,text):\n",
        "    if pd.isnull(title):\n",
        "        return text\n",
        "    else:\n",
        "        return title + '. ' + text"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1FGFA1jSr52"
      },
      "source": [
        "productSentiment['review'] = productSentiment.apply(lambda x: concatTitleText(x['reviews_title'],x['reviews_text']),axis=1)\n",
        "productSentiment.drop(['reviews_title','reviews_text'],axis=1,inplace=True)"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxizQjugUgOI"
      },
      "source": [
        "productSentiment = productSentiment.reindex(columns=['review','user_sentiment']) "
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14sIT0yeX3R9"
      },
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "def clean_text(text):\n",
        "    delete_dict = {sp_character: '' for sp_character in string.punctuation} \n",
        "    delete_dict[' '] = ' '\n",
        "    table = str.maketrans(delete_dict)\n",
        "    text1 = text.translate(table)\n",
        "    textArr= text1.split()\n",
        "    text2 = ' '.join([w for w in textArr if ( not w.isdigit() and ( not w.isdigit() and len(w)>3) )]) \n",
        "    text3 = re.sub(r'[^\\w\\s]','',text2)\n",
        "    return text3.lower()"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXnrz9x9WEEy"
      },
      "source": [
        "productSentiment['review'] = productSentiment['review'].apply(clean_text)"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Mcl_fs74WLlN",
        "outputId": "1eae5c39-ea36-4cad-e6f4-2487abdbed29"
      },
      "source": [
        "productSentiment.head()"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>user_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>just awesome love this album very good more si...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>good good flavor this review collected part pr...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>disappointed read through reviews here before ...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>irritation husband bought this caused irritati...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>worth boyfriend bought this spice things bedro...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review user_sentiment\n",
              "0  just awesome love this album very good more si...       Positive\n",
              "1  good good flavor this review collected part pr...       Positive\n",
              "3  disappointed read through reviews here before ...       Negative\n",
              "4  irritation husband bought this caused irritati...       Negative\n",
              "5  worth boyfriend bought this spice things bedro...       Negative"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lp9PAtoH4zpg",
        "outputId": "0fa98201-be12-42a4-9d74-b785f95c6989"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "# function to remove stopwords\n",
        "def remove_stopwords(text):\n",
        "    textArr = text.split(' ')\n",
        "    rem_text = \" \".join([i for i in textArr if i not in stop_words])\n",
        "    return rem_text"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHVOUh4KU3XL"
      },
      "source": [
        "productSentiment['review']=productSentiment['review'].apply(remove_stopwords)"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Jh4g74Sm8N_I",
        "outputId": "b509df03-33b4-4d23-9c01-aa4aa230aa97"
      },
      "source": [
        "productSentiment.head()"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>user_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>awesome love album good side current sound hyp...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>good good flavor review collected part promotion</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>disappointed read reviews looking buying coupl...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>irritation husband bought caused irritation fe...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>worth boyfriend bought spice things bedroom hi...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review user_sentiment\n",
              "0  awesome love album good side current sound hyp...       Positive\n",
              "1   good good flavor review collected part promotion       Positive\n",
              "3  disappointed read reviews looking buying coupl...       Negative\n",
              "4  irritation husband bought caused irritation fe...       Negative\n",
              "5  worth boyfriend bought spice things bedroom hi...       Negative"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1bav7rXwLcS"
      },
      "source": [
        "### Task #3 - Feature Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSGbMCy23T21"
      },
      "source": [
        "#### Test Train split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvZZjg_pi4Mb",
        "outputId": "767b2f0b-c6fb-4a00-dd6d-bd180d6f02a2"
      },
      "source": [
        "products['reviews_text'].head()"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    i love this album. it's very good. more to the...\n",
              "1    Good flavor. This review was collected as part...\n",
              "3    I read through the reviews on here before look...\n",
              "4    My husband bought this gel for us. The gel cau...\n",
              "5    My boyfriend and I bought this to spice things...\n",
              "Name: reviews_text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsuY2HN13a0_"
      },
      "source": [
        "X = productSentiment['review']\n",
        "productSentiment['user_sentiment'] = np.where((productSentiment['user_sentiment'] == 'Positive'), 1, 0)\n",
        "y = productSentiment['user_sentiment']"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AQWsGNy1Vek"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "\n",
        "text_list=X_train.tolist()\n",
        "test_text_list=X_test.tolist()"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etfkssEUly3g"
      },
      "source": [
        "#### Count Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrZtXp367yJN"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vect = CountVectorizer(stop_words='english',max_features=5000)\n",
        "vect.fit(text_list)\n",
        "X_train_tf = vect.transform(text_list)\n",
        "X_test_tf =vect.transform(test_text_list)"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEbHHBGnyGCZ"
      },
      "source": [
        "#### TF_IDF Vecotrizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcsg4xR6yKFO"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidfconverter = TfidfVectorizer(max_features=5000, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n",
        "X_train = tfidfconverter.fit_transform(text_list).toarray()\n",
        "X_test = tfidfconverter.transform(test_text_list).toarray()"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyPGg8wf3rzN"
      },
      "source": [
        "### Task #4 - Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9B0CdqEsEsv"
      },
      "source": [
        "#### Common Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykT_QO96h4dr"
      },
      "source": [
        "def calcMetrics(confusion,metrics):\n",
        "    TP = confusion[1,1] # true positive \n",
        "    TN = confusion[0,0] # true negatives\n",
        "    FP = confusion[0,1] # false positives\n",
        "    FN = confusion[1,0] # false negatives \n",
        "    metrics['Sensitivity'] = TP / float(TP+FN)\n",
        "    metrics['Precision'] = TP / float(TP + FP)\n",
        "    metrics['Specificity'] = TN / float(TN+FP)\n",
        "    return metrics"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtnL7DjngjWr"
      },
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "def evaluate_model(X,y,model):\n",
        "    metrics = dict()\n",
        "    metrics['Accuracy'] = accuracy_score(y, model.predict(X))\n",
        "    c_m =confusion_matrix(y, model.predict(X))\n",
        "    return calcMetrics(c_m,metrics)"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-71gQUUB3-vB"
      },
      "source": [
        "modelCompare = pd.DataFrame()"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEfnYp3EVG7r"
      },
      "source": [
        "#### Task #3 Handling Class Imbalance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9O5cI5taVGMK"
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MB8pC1mbwfdD"
      },
      "source": [
        "##### Using SMOTE on CountVectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8V_dg8kvp5Pj",
        "outputId": "86d9a83a-6842-4d51-986b-764081f8772e"
      },
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "print('Before',Counter(y_train))\n",
        "# oversampling the train dataset using SMOTE\n",
        "smt = SMOTE()\n",
        "X_train_tf_sm, y_train_tf_sm = smt.fit_resample(X_train_tf, y_train)\n",
        "print('After',Counter(y_train_tf_sm))"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before Counter({1: 17174, 0: 2136})\n",
            "After Counter({1: 17174, 0: 17174})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiGv-L9Vtcu2"
      },
      "source": [
        "##### Using SMOTE on TF-IDFVectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0PEEmQCtQR3",
        "outputId": "f0f3f615-df5c-46c1-e696-a3011f78868f"
      },
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "print('Before',Counter(y_train))\n",
        "# oversampling the train dataset using SMOTE\n",
        "smt = SMOTE()\n",
        "X_train_sm, y_train_sm = smt.fit_resample(X_train, y_train)\n",
        "\n",
        "print('After',Counter(y_train_sm))"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before Counter({1: 17174, 0: 2136})\n",
            "After Counter({1: 17174, 0: 17174})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zsyy0PTV4-ft"
      },
      "source": [
        "#### Naive Base methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apV0tNKP5JsU"
      },
      "source": [
        "##### Bernoulli NB first"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Z-fit2dT54Ku",
        "outputId": "12e8fba2-df1a-4df0-f5d0-b091ae5d92b6"
      },
      "source": [
        "from sklearn.naive_bayes import BernoulliNB\n",
        "bnb1 = BernoulliNB()\n",
        "bnb1.fit(X_train_tf,y_train)\n",
        "print(evaluate_model(X_train_tf, y_train,bnb1))\n",
        "print(evaluate_model(X_test_tf, y_test,bnb1))\n",
        "modelCompare = modelCompare.append(pd.Series(evaluate_model(X_test_tf, y_test,bnb1),name='Bernoulli NB TF Imbalance'))\n",
        "modelCompare.tail(1)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Accuracy': 0.8887622993267736, 'Sensitivity': 0.9475952020496099, 'Precision': 0.9287752539664422, 'Specificity': 0.4157303370786517}\n",
            "{'Accuracy': 0.8737312711454809, 'Sensitivity': 0.9471395570050278, 'Precision': 0.9139784946236559, 'Specificity': 0.2846237731733915}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Sensitivity</th>\n",
              "      <th>Specificity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Bernoulli NB TF Imbalance</th>\n",
              "      <td>0.873731</td>\n",
              "      <td>0.913978</td>\n",
              "      <td>0.94714</td>\n",
              "      <td>0.284624</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           Accuracy  Precision  Sensitivity  Specificity\n",
              "Bernoulli NB TF Imbalance  0.873731   0.913978      0.94714     0.284624"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "yOaQm63av7Dy",
        "outputId": "33604088-25f3-495e-da6b-80a4aa88dd2b"
      },
      "source": [
        "from sklearn.naive_bayes import BernoulliNB\n",
        "bnb2 = BernoulliNB()\n",
        "bnb2.fit(X_train_tf_sm,y_train_tf_sm)\n",
        "print(evaluate_model(X_train_tf_sm, y_train_tf_sm,bnb2))\n",
        "print(evaluate_model(X_test_tf, y_test,bnb2))\n",
        "modelCompare = modelCompare.append(pd.Series(evaluate_model(X_test_tf, y_test,bnb2),name='Bernoulli NB TF SMOTE'))\n",
        "modelCompare.tail(1)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Accuracy': 0.8756550599743799, 'Sensitivity': 0.823337603353907, 'Precision': 0.9195551798140079, 'Specificity': 0.9279725165948527}\n",
            "{'Accuracy': 0.7667955534074432, 'Sensitivity': 0.8119309688816415, 'Precision': 0.9162705106578746, 'Specificity': 0.40458015267175573}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Sensitivity</th>\n",
              "      <th>Specificity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Bernoulli NB TF SMOTE</th>\n",
              "      <td>0.766796</td>\n",
              "      <td>0.916271</td>\n",
              "      <td>0.811931</td>\n",
              "      <td>0.40458</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Accuracy  Precision  Sensitivity  Specificity\n",
              "Bernoulli NB TF SMOTE  0.766796   0.916271     0.811931      0.40458"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1m3t6bBg5OgR"
      },
      "source": [
        "##### Multinomial NB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "xpRIXeBE579s",
        "outputId": "39bccfa9-56a8-4a05-f8d5-97dcf40d362b"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "mnb1 = MultinomialNB()\n",
        "#fit on training data\n",
        "mnb1.fit(X_train_tf, y_train)\n",
        "\n",
        "print(evaluate_model(X_train_tf, y_train,mnb1))\n",
        "print(evaluate_model(X_test_tf, y_test,mnb1))\n",
        "\n",
        "modelCompare = modelCompare.append(pd.Series(evaluate_model(X_test_tf, y_test,mnb1),name='Bernoulli MB TF Imbalance'))\n",
        "modelCompare.tail(1)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Accuracy': 0.8907301916105644, 'Sensitivity': 0.9464888785373239, 'Precision': 0.9317322022240055, 'Specificity': 0.44241573033707865}\n",
            "{'Accuracy': 0.874939584340261, 'Sensitivity': 0.9449653485527925, 'Precision': 0.9169303797468354, 'Specificity': 0.31297709923664124}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Sensitivity</th>\n",
              "      <th>Specificity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Bernoulli MB TF Imbalance</th>\n",
              "      <td>0.87494</td>\n",
              "      <td>0.91693</td>\n",
              "      <td>0.944965</td>\n",
              "      <td>0.312977</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           Accuracy  Precision  Sensitivity  Specificity\n",
              "Bernoulli MB TF Imbalance   0.87494    0.91693     0.944965     0.312977"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "7wueNbeCvH6B",
        "outputId": "2b5cbb4b-1cfa-4c16-c80e-6da448b1fc7a"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "mnb2 = MultinomialNB()\n",
        "#fit on training data\n",
        "mnb2.fit(X_train_tf_sm, y_train_tf_sm)\n",
        "\n",
        "print(evaluate_model(X_train_tf_sm, y_train_tf_sm,mnb2))\n",
        "print(evaluate_model(X_test_tf, y_test,mnb2))\n",
        "\n",
        "modelCompare = modelCompare.append(pd.Series(evaluate_model(X_test_tf, y_test,mnb2),name='Bernoulli MB TF SMOTE'))\n",
        "modelCompare.tail(1)"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Accuracy': 0.8467741935483871, 'Sensitivity': 0.8574007220216606, 'Precision': 0.8395575574434119, 'Specificity': 0.8361476650751135}\n",
            "{'Accuracy': 0.8135572740454325, 'Sensitivity': 0.8540562576437016, 'Precision': 0.9305596683446846, 'Specificity': 0.48854961832061067}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Sensitivity</th>\n",
              "      <th>Specificity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Bernoulli MB TF SMOTE</th>\n",
              "      <td>0.813557</td>\n",
              "      <td>0.93056</td>\n",
              "      <td>0.854056</td>\n",
              "      <td>0.48855</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Accuracy  Precision  Sensitivity  Specificity\n",
              "Bernoulli MB TF SMOTE  0.813557    0.93056     0.854056      0.48855"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "pRv9u504_EG4",
        "outputId": "ece6d146-50c3-4c40-9b38-61e74c1ab86d"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "mnb3 = MultinomialNB()\n",
        "#fit on training data\n",
        "mnb3.fit(X_train, y_train)\n",
        "\n",
        "print(evaluate_model(X_train, y_train,mnb3))\n",
        "print(evaluate_model(X_test, y_test,mnb3))\n",
        "\n",
        "modelCompare = modelCompare.append(pd.Series(evaluate_model(X_test, y_test,mnb3),name='Bernoulli MB TF-IDF Imbalance'))\n",
        "modelCompare.tail(1)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Accuracy': 0.8958052822371828, 'Sensitivity': 0.9967974845696984, 'Precision': 0.897410358565737, 'Specificity': 0.08380149812734082}\n",
            "{'Accuracy': 0.889681005316578, 'Sensitivity': 0.9963310232368529, 'Precision': 0.8921878802628377, 'Specificity': 0.03380588876772083}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Sensitivity</th>\n",
              "      <th>Specificity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Bernoulli MB TF-IDF Imbalance</th>\n",
              "      <td>0.889681</td>\n",
              "      <td>0.892188</td>\n",
              "      <td>0.996331</td>\n",
              "      <td>0.033806</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               Accuracy  Precision  Sensitivity  Specificity\n",
              "Bernoulli MB TF-IDF Imbalance  0.889681   0.892188     0.996331     0.033806"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "5LTac8sr_O7I",
        "outputId": "973a5cf3-ba8b-4e2f-a686-35ff645590ff"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "mnb4 = MultinomialNB()\n",
        "#fit on training data\n",
        "mnb4.fit(X_train_sm, y_train_sm)\n",
        "\n",
        "print(evaluate_model(X_train_sm, y_train_sm,mnb4))\n",
        "print(evaluate_model(X_test, y_test,mnb4))\n",
        "\n",
        "modelCompare = modelCompare.append(pd.Series(evaluate_model(X_test, y_test,mnb4),name='Bernoulli MB TF-IDF SMOTE'))\n",
        "modelCompare.tail(1)"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Accuracy': 0.8396122044951672, 'Sensitivity': 0.8579247700011645, 'Precision': 0.8276133235971466, 'Specificity': 0.8212996389891697}\n",
            "{'Accuracy': 0.8125906234896085, 'Sensitivity': 0.8385650224215246, 'Precision': 0.9444444444444444, 'Specificity': 0.604143947655398}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Sensitivity</th>\n",
              "      <th>Specificity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Bernoulli MB TF-IDF SMOTE</th>\n",
              "      <td>0.812591</td>\n",
              "      <td>0.944444</td>\n",
              "      <td>0.838565</td>\n",
              "      <td>0.604144</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           Accuracy  Precision  Sensitivity  Specificity\n",
              "Bernoulli MB TF-IDF SMOTE  0.812591   0.944444     0.838565     0.604144"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uF_fKwcl6PFy"
      },
      "source": [
        "#### Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxSKHKVimsSP"
      },
      "source": [
        "##### Logistic Regression with balanced class weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "OXmlO00k6mRL",
        "outputId": "b23190a4-4c83-4766-9bff-efcb4c6f0c05"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg1 = LogisticRegression(random_state=42, C = 3.5, class_weight= 'balanced')\n",
        "logreg1.fit(X_train,y_train)\n",
        "print(evaluate_model(X_train, y_train,logreg1))\n",
        "print(evaluate_model(X_test, y_test,logreg1))\n",
        "modelCompare = modelCompare.append(pd.Series(evaluate_model(X_test, y_test,logreg1),name='LR Class weight Balanced'))\n",
        "modelCompare.tail(1)"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Accuracy': 0.9108234075608493, 'Sensitivity': 0.9038663095376732, 'Precision': 0.9954469667820957, 'Specificity': 0.9667602996254682}\n",
            "{'Accuracy': 0.8721604639922668, 'Sensitivity': 0.8831362956923495, 'Precision': 0.9704345229207108, 'Specificity': 0.7840785169029444}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Sensitivity</th>\n",
              "      <th>Specificity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LR Class weight Balanced</th>\n",
              "      <td>0.87216</td>\n",
              "      <td>0.970435</td>\n",
              "      <td>0.883136</td>\n",
              "      <td>0.784079</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          Accuracy  Precision  Sensitivity  Specificity\n",
              "LR Class weight Balanced   0.87216   0.970435     0.883136     0.784079"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "XcPcq9_EBd6K",
        "outputId": "aa5176eb-1c44-4fe3-a1ae-476c2be26c7c"
      },
      "source": [
        "logreg2 = LogisticRegression(random_state=42, C = 3.5)\n",
        "logreg2.fit(X_train_sm,y_train_sm)\n",
        "print(evaluate_model(X_train_sm, y_train_sm,logreg2))\n",
        "print(evaluate_model(X_test, y_test,logreg2))\n",
        "modelCompare = modelCompare.append(pd.Series(evaluate_model(X_test, y_test,logreg2),name='LR SMOTE'))\n",
        "modelCompare.tail(1)"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Accuracy': 0.9569407243507628, 'Sensitivity': 0.9425876324676837, 'Precision': 0.9704454169414304, 'Specificity': 0.9712938162338418}\n",
            "{'Accuracy': 0.8908893185113581, 'Sensitivity': 0.9152058703628211, 'Precision': 0.9602224123182207, 'Specificity': 0.6957470010905126}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Sensitivity</th>\n",
              "      <th>Specificity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LR SMOTE</th>\n",
              "      <td>0.890889</td>\n",
              "      <td>0.960222</td>\n",
              "      <td>0.915206</td>\n",
              "      <td>0.695747</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Accuracy  Precision  Sensitivity  Specificity\n",
              "LR SMOTE  0.890889   0.960222     0.915206     0.695747"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4u8kSmrCot0"
      },
      "source": [
        "#### Classification Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IG3Tz2BpkWUL"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4stBHvQxC7Wn"
      },
      "source": [
        "##### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "id": "UA5Z_p-NdyLM",
        "outputId": "94ad6d7b-c9cc-4223-c832-6415720f135c"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf1 = RandomForestClassifier(class_weight='balanced', max_depth=4, max_features=10,\n",
        "                       min_samples_leaf=5, n_estimators=50, n_jobs=-1,\n",
        "                       random_state=42)\n",
        "rf1.fit(X_train, y_train)\n",
        "print(evaluate_model(X_train, y_train,rf1))\n",
        "print(evaluate_model(X_test,y_test,rf1))\n",
        "modelCompare = modelCompare.append(pd.Series(evaluate_model(X_test, y_test,rf1),name='RF Balanced No Tuning'))\n",
        "modelCompare.tail(1)"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Accuracy': 0.6954945624029001, 'Sensitivity': 0.687434494002562, 'Precision': 0.9584348108459165, 'Specificity': 0.7602996254681648}\n",
            "{'Accuracy': 0.6806428226196231, 'Sensitivity': 0.6793042532952847, 'Precision': 0.9464218099204846, 'Specificity': 0.6913849509269356}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Sensitivity</th>\n",
              "      <th>Specificity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>RF Balanced No Tuning</th>\n",
              "      <td>0.680643</td>\n",
              "      <td>0.946422</td>\n",
              "      <td>0.679304</td>\n",
              "      <td>0.691385</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Accuracy  Precision  Sensitivity  Specificity\n",
              "RF Balanced No Tuning  0.680643   0.946422     0.679304     0.691385"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "id": "NXNiNCqRCzi9",
        "outputId": "7225a254-36b6-484d-bd86-8198d600927e"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf2 = RandomForestClassifier(max_depth=4, max_features=10,\n",
        "                       min_samples_leaf=5, n_estimators=50, n_jobs=-1,\n",
        "                       random_state=42)\n",
        "rf2.fit(X_train_sm, y_train_sm)\n",
        "print(evaluate_model(X_train_sm, y_train_sm,rf2))\n",
        "print(evaluate_model(X_test,y_test,rf2))\n",
        "modelCompare = modelCompare.append(pd.Series(evaluate_model(X_test, y_test,rf2),name='RF SMOTE No Tuning'))\n",
        "modelCompare.tail(1)"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Accuracy': 0.7708745778502387, 'Sensitivity': 0.7334924886456271, 'Precision': 0.7927627438640654, 'Specificity': 0.8082566670548503}\n",
            "{'Accuracy': 0.7102464958917352, 'Sensitivity': 0.7252344068487566, 'Precision': 0.9341851916681253, 'Specificity': 0.5899672846237731}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Sensitivity</th>\n",
              "      <th>Specificity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>RF SMOTE No Tuning</th>\n",
              "      <td>0.710246</td>\n",
              "      <td>0.934185</td>\n",
              "      <td>0.725234</td>\n",
              "      <td>0.589967</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Accuracy  Precision  Sensitivity  Specificity\n",
              "RF SMOTE No Tuning  0.710246   0.934185     0.725234     0.589967"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsBeAQsjSxsa",
        "outputId": "7c1b9f07-0b2c-4867-e8e8-82ae36dfb72a"
      },
      "source": [
        "%%time\n",
        "classifier_rf = RandomForestClassifier(random_state=42, n_jobs=-1,class_weight=\"balanced\")\n",
        "# Create the parameter grid based on the results of random search \n",
        "params = {\n",
        "    'max_depth': [4,5,10,15],\n",
        "    'min_samples_leaf': [5, 10, 20],\n",
        "    'max_features': [10,20],\n",
        "    'n_estimators': [30, 50,60]\n",
        "}\n",
        "# Instantiate the grid search model\n",
        "grid_search = GridSearchCV(estimator=classifier_rf, param_grid=params, \n",
        "                          cv=4, n_jobs=-1, verbose=1,scoring = \"recall\")\n",
        "grid_search.fit(X_train,y_train)\n",
        "rf3 = grid_search.best_estimator_\n",
        "print(evaluate_model(X_train, y_train,rf3))\n",
        "print(evaluate_model(X_test, y_test,rf3))\n",
        "modelCompare = modelCompare.append(pd.Series(evaluate_model(X_test, y_test,rf3),name='RF Best Balanced'))\n",
        "modelCompare.tail(1)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 4 folds for each of 72 candidates, totalling 288 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   35.5s\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:  3.0min\n",
            "[Parallel(n_jobs=-1)]: Done 288 out of 288 | elapsed:  5.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'Accuracy': 0.8034697048161574, 'Sensitivity': 0.8005124024688482, 'Precision': 0.9738613019763406, 'Specificity': 0.827247191011236}\n",
            "{'Accuracy': 0.7850410826486225, 'Sensitivity': 0.7933143090093763, 'Precision': 0.9576771653543307, 'Specificity': 0.7186477644492911}\n",
            "CPU times: user 12.7 s, sys: 947 ms, total: 13.7 s\n",
            "Wall time: 5min 25s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTaZ9fAbZDBO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "d6f9583a-9f7d-4329-e72f-1c9d24787a70"
      },
      "source": [
        "from sklearn.metrics import plot_roc_curve\n",
        "plot_roc_curve(rf3, X_train, y_train)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x7feeaf282150>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdCtxrpEDkRS",
        "outputId": "a7f84dca-10e0-4570-f233-6ffa6183ff7c"
      },
      "source": [
        "%%time\n",
        "classifier_rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "# Create the parameter grid based on the results of random search \n",
        "params = {\n",
        "    'max_depth': [4,5,10,15],\n",
        "    'min_samples_leaf': [5, 10, 20],\n",
        "    'max_features': [10,20],\n",
        "    'n_estimators': [30, 50,60]\n",
        "}\n",
        "# Instantiate the grid search model\n",
        "grid_search = GridSearchCV(estimator=classifier_rf, param_grid=params, \n",
        "                          cv=4, n_jobs=-1, verbose=1,scoring = \"recall\")\n",
        "grid_search.fit(X_train_sm,y_train_sm)\n",
        "rf4 = grid_search.best_estimator_\n",
        "print(evaluate_model(X_train_sm, y_train_sm,rf4))\n",
        "print(evaluate_model(X_test, y_test,rf4))\n",
        "modelCompare = modelCompare.append(pd.Series(evaluate_model(X_test, y_test,rf4),name='RF Best SMOTE'))\n",
        "modelCompare.tail(1)"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 4 folds for each of 72 candidates, totalling 288 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   58.3s\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:  5.2min\n",
            "[Parallel(n_jobs=-1)]: Done 288 out of 288 | elapsed:  9.5min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'Accuracy': 0.8169616862699429, 'Sensitivity': 0.7966693839524863, 'Precision': 0.8303696061176185, 'Specificity': 0.8372539885873995}\n",
            "{'Accuracy': 0.7672788786853553, 'Sensitivity': 0.7874711237939938, 'Precision': 0.9412051323696605, 'Specificity': 0.6052344601962922}\n",
            "CPU times: user 19.4 s, sys: 1.55 s, total: 20.9 s\n",
            "Wall time: 9min 40s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "lRp71y8pY20P",
        "outputId": "aedc7f55-94de-480c-fc78-6cb7c44b5142"
      },
      "source": [
        "plot_roc_curve(rf4, X_train_sm, y_train_sm)"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x7feeafab7590>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFx35NnYC06E"
      },
      "source": [
        "##### XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "id": "MxkAz6WEj29N",
        "outputId": "8919180a-00d9-45ea-ec2b-7c140bf92f42"
      },
      "source": [
        "#xgboost using default parameters\n",
        "import xgboost as xgb\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_auc_score\n",
        "xgclf1 = xgb.XGBClassifier()\n",
        "xgclf1.fit(X_train, y_train)\n",
        "y_train_pred_prob=xgclf1.predict_proba(X_train)[:, 1]\n",
        "y_test_pred_prob=xgclf1.predict_proba(X_test)[:, 1]\n",
        "print('AUC on train data by XGBoost =', roc_auc_score(y_true=y_train,y_score=y_train_pred_prob))\n",
        "print('AUC on test data by XGBoost =', roc_auc_score(y_true=y_test,y_score=y_test_pred_prob))\n",
        "print(evaluate_model(X_train, y_train,xgclf1))\n",
        "print(evaluate_model(X_test, y_test,xgclf1))\n",
        "modelCompare = modelCompare.append(pd.Series(evaluate_model(X_test, y_test,xgclf1),name='XG Boost No Tuning Imbalanced'))\n",
        "modelCompare.tail(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC on train data by XGBoost = 0.8934641997593262\n",
            "AUC on test data by XGBoost = 0.8731894253922118\n",
            "{'Accuracy': 0.8970481615743138, 'Sensitivity': 0.9990683591475487, 'Precision': 0.8969158389963409, 'Specificity': 0.07677902621722846}\n",
            "{'Accuracy': 0.8935476075398744, 'Sensitivity': 0.9979616795760293, 'Precision': 0.8945188794153471, 'Specificity': 0.05561613958560523}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Sensitivity</th>\n",
              "      <th>Specificity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>XG Boost No Tuning Imbalanced</th>\n",
              "      <td>0.893548</td>\n",
              "      <td>0.894519</td>\n",
              "      <td>0.997962</td>\n",
              "      <td>0.055616</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               Accuracy  Precision  Sensitivity  Specificity\n",
              "XG Boost No Tuning Imbalanced  0.893548   0.894519     0.997962     0.055616"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "id": "Tj2pG7EPfZ4A",
        "outputId": "0c3453cd-1296-467e-8496-927424b4e4e4"
      },
      "source": [
        "#xgboost using default parameters\n",
        "import xgboost as xgb\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_auc_score\n",
        "xgclf2 = xgb.XGBClassifier()\n",
        "xgclf2.fit(X_train_sm, y_train_sm)\n",
        "y_train_pred_prob=xgclf2.predict_proba(X_train_sm)[:, 1]\n",
        "y_test_pred_prob=xgclf2.predict_proba(X_test)[:, 1]\n",
        "print('AUC on train data by XGBoost =', roc_auc_score(y_true=y_train_sm,y_score=y_train_pred_prob))\n",
        "print('AUC on test data by XGBoost =', roc_auc_score(y_true=y_test,y_score=y_test_pred_prob))\n",
        "print(evaluate_model(X_train_sm, y_train_sm,xgclf2))\n",
        "print(evaluate_model(X_test, y_test,xgclf2))\n",
        "modelCompare = modelCompare.append(pd.Series(evaluate_model(X_test, y_test,xgclf2),name='XG Boost No Tuning SMOTE'))\n",
        "modelCompare.tail(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC on train data by XGBoost = 0.9282462681441009\n",
            "AUC on test data by XGBoost = 0.866838475368924\n",
            "{'Accuracy': 0.8371375334808432, 'Sensitivity': 0.8261907534645394, 'Precision': 0.8446838909393976, 'Specificity': 0.8480843134971469}\n",
            "{'Accuracy': 0.805461575640406, 'Sensitivity': 0.8198124745209947, 'Precision': 0.9550419502928605, 'Specificity': 0.6902944383860414}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Sensitivity</th>\n",
              "      <th>Specificity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>XG Boost No Tuning SMOTE</th>\n",
              "      <td>0.805462</td>\n",
              "      <td>0.955042</td>\n",
              "      <td>0.819812</td>\n",
              "      <td>0.690294</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          Accuracy  Precision  Sensitivity  Specificity\n",
              "XG Boost No Tuning SMOTE  0.805462   0.955042     0.819812     0.690294"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeBbwjq1hFWv"
      },
      "source": [
        "import xgboost as xgb\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_auc_score\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-G1vZAtvFDQc"
      },
      "source": [
        "#xgboost using hyper parameter tuning\n",
        "\n",
        "xgb_model = xgb.XGBClassifier(n_jobs=-1,\n",
        "                              random_state=42,\n",
        "                              use_label_encoder=False,\n",
        "                              objective = \"binary:logistic\",\n",
        "                              nthread = -1,\n",
        "                              eval_metric='auc')\n",
        "parameters = {'learning_rate': [0.2,0.3],\n",
        "              'max_depth': [2,4,],\n",
        "              'min_child_weight': [1,10],\n",
        "              'n_estimators': [50, 100]}\n",
        "\n",
        "scorer = metrics.make_scorer(metrics.roc_auc_score,\n",
        "                             greater_is_better=True,\n",
        "                             needs_proba=True,\n",
        "                             needs_threshold=False)\n",
        "\n",
        "clf_xgb = GridSearchCV(estimator=xgb_model,\n",
        "                                       param_grid=parameters,\n",
        "                                       n_jobs=-1,\n",
        "                                       cv=3,\n",
        "                                       scoring=scorer,\n",
        "                                       refit=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DVY6e8iGXiR"
      },
      "source": [
        "# clf_xgb.fit(X_train_sm, y_train_sm)"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dy5jkPztkai2"
      },
      "source": [
        "# xgclf3 = xgb.XGBClassifier()\n",
        "# xgclf3.fit(X_train_sm, y_train_sm)\n",
        "# y_train_pred_prob=final_model.predict_proba(X_train_sm)[:, 1]\n",
        "# y_test_pred_prob=final_model.predict_proba(X_test)[:, 1]\n",
        "# print('AUC on train data by XGBoost =', metrics.roc_auc_score(y_true=y_train_sm,y_score=y_train_pred_prob))\n",
        "# print('AUC on test data by XGBoost =', metrics.roc_auc_score(y_true=y_test,y_score=y_test_pred_prob))\n",
        "# print(evaluate_model(X_train_sm, y_train_sm,xgclf3))\n",
        "# print(evaluate_model(X_test, y_test,xgclf3))\n",
        "# modelCompare = modelCompare.append(pd.Series(evaluate_model(X_test, y_test,clf_xgb_best),name='XG Boost Best SMOTE'))\n",
        "# modelCompare.tail(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a485Tbd1DGBd"
      },
      "source": [
        "#### Model Comparision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXUr4S7a_2Xn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "outputId": "b855e449-326c-4842-cc29-efc3bb2b6089"
      },
      "source": [
        "modelCompare"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Sensitivity</th>\n",
              "      <th>Specificity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Bernoulli NB TF Imbalance</th>\n",
              "      <td>0.873731</td>\n",
              "      <td>0.913978</td>\n",
              "      <td>0.947140</td>\n",
              "      <td>0.284624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bernoulli NB TF SMOTE</th>\n",
              "      <td>0.767400</td>\n",
              "      <td>0.916974</td>\n",
              "      <td>0.811931</td>\n",
              "      <td>0.410033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bernoulli MB TF Imbalance</th>\n",
              "      <td>0.874940</td>\n",
              "      <td>0.916930</td>\n",
              "      <td>0.944965</td>\n",
              "      <td>0.312977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bernoulli MB TF SMOTE</th>\n",
              "      <td>0.816216</td>\n",
              "      <td>0.931167</td>\n",
              "      <td>0.856638</td>\n",
              "      <td>0.491821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bernoulli MB TF-IDF Imbalance</th>\n",
              "      <td>0.889681</td>\n",
              "      <td>0.892188</td>\n",
              "      <td>0.996331</td>\n",
              "      <td>0.033806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bernoulli MB TF-IDF SMOTE</th>\n",
              "      <td>0.815732</td>\n",
              "      <td>0.945208</td>\n",
              "      <td>0.841555</td>\n",
              "      <td>0.608506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LR Class weight Balanced</th>\n",
              "      <td>0.872160</td>\n",
              "      <td>0.970435</td>\n",
              "      <td>0.883136</td>\n",
              "      <td>0.784079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LR SMOTE</th>\n",
              "      <td>0.891977</td>\n",
              "      <td>0.961324</td>\n",
              "      <td>0.915342</td>\n",
              "      <td>0.704471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RF Balanced No Tuning</th>\n",
              "      <td>0.680643</td>\n",
              "      <td>0.946422</td>\n",
              "      <td>0.679304</td>\n",
              "      <td>0.691385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RF SMOTE No Tuning</th>\n",
              "      <td>0.715442</td>\n",
              "      <td>0.933172</td>\n",
              "      <td>0.732436</td>\n",
              "      <td>0.579062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RF Best Balanced</th>\n",
              "      <td>0.785041</td>\n",
              "      <td>0.957677</td>\n",
              "      <td>0.793314</td>\n",
              "      <td>0.718648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RF Best SMOTE</th>\n",
              "      <td>0.759304</td>\n",
              "      <td>0.941147</td>\n",
              "      <td>0.777959</td>\n",
              "      <td>0.609597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XG Boost No Tuning Imbalanced</th>\n",
              "      <td>0.893548</td>\n",
              "      <td>0.894519</td>\n",
              "      <td>0.997962</td>\n",
              "      <td>0.055616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XG Boost No Tuning SMOTE</th>\n",
              "      <td>0.805462</td>\n",
              "      <td>0.955042</td>\n",
              "      <td>0.819812</td>\n",
              "      <td>0.690294</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               Accuracy  Precision  Sensitivity  Specificity\n",
              "Bernoulli NB TF Imbalance      0.873731   0.913978     0.947140     0.284624\n",
              "Bernoulli NB TF SMOTE          0.767400   0.916974     0.811931     0.410033\n",
              "Bernoulli MB TF Imbalance      0.874940   0.916930     0.944965     0.312977\n",
              "Bernoulli MB TF SMOTE          0.816216   0.931167     0.856638     0.491821\n",
              "Bernoulli MB TF-IDF Imbalance  0.889681   0.892188     0.996331     0.033806\n",
              "Bernoulli MB TF-IDF SMOTE      0.815732   0.945208     0.841555     0.608506\n",
              "LR Class weight Balanced       0.872160   0.970435     0.883136     0.784079\n",
              "LR SMOTE                       0.891977   0.961324     0.915342     0.704471\n",
              "RF Balanced No Tuning          0.680643   0.946422     0.679304     0.691385\n",
              "RF SMOTE No Tuning             0.715442   0.933172     0.732436     0.579062\n",
              "RF Best Balanced               0.785041   0.957677     0.793314     0.718648\n",
              "RF Best SMOTE                  0.759304   0.941147     0.777959     0.609597\n",
              "XG Boost No Tuning Imbalanced  0.893548   0.894519     0.997962     0.055616\n",
              "XG Boost No Tuning SMOTE       0.805462   0.955042     0.819812     0.690294"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaZnjdfmxyEY"
      },
      "source": [
        "####Plotting the ROC Curve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEF3YkHxx3s5"
      },
      "source": [
        "#### Finding Optimal Cutoff Point"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAEAmDxH8XOF"
      },
      "source": [
        "#### Pickling the Best Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9K6E-ktv8MkH"
      },
      "source": [
        "# import pickle\n",
        "# pickle.dump(logreg1,open('/content/gdrive/MyDrive/Colab Data/logreg_scenario_1.pkl','wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2l9lrqFtsNn"
      },
      "source": [
        "# products_all = pd.read_csv('/content/gdrive/MyDrive/Colab Data/sample30.csv')\n",
        "# X_transformed_LR_scenario_1=tfidfconverter.transform(products_all['reviews_text'].tolist())\n",
        "# np.savez_compressed(open('/content/gdrive/MyDrive/Colab Data/X_transformed_LR_scenario_1.npz','wb'),X_transformed_LR_scenario_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0hZT7AN07xl"
      },
      "source": [
        "## Task #5 - Recommendation Engine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1srcqQol2rV5"
      },
      "source": [
        "#### Create a Product Name/Category - Product Id Mapping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRbI6MvUQmef"
      },
      "source": [
        "productMapping = products.drop_duplicates(subset='productId',keep='first')[['productId','name','categories']]"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUerEa-MRTyg",
        "outputId": "0259fb7e-b910-4904-d920-d7799f1076e9"
      },
      "source": [
        "productMapping.shape"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(271, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "IdTcXEYUSWFf",
        "outputId": "9b66d449-cb10-4016-b568-b171e4eb155d"
      },
      "source": [
        "productMapping.head()"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>productId</th>\n",
              "      <th>name</th>\n",
              "      <th>categories</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AV13O1A8GV-KLJ3akUyj</td>\n",
              "      <td>Pink Friday: Roman Reloaded Re-Up (w/dvd)</td>\n",
              "      <td>Movies, Music &amp; Books,Music,R&amp;b,Movies &amp; TV,Mo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AV14LG0R-jtxr-f38QfS</td>\n",
              "      <td>Lundberg Organic Cinnamon Toast Rice Cakes</td>\n",
              "      <td>Food,Packaged Foods,Snacks,Crackers,Snacks, Co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AV16khLE-jtxr-f38VFn</td>\n",
              "      <td>K-Y Love Sensuality Pleasure Gel</td>\n",
              "      <td>Personal Care,Medicine Cabinet,Lubricant/Sperm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>AV1d76w7vKc47QAVhCqn</td>\n",
              "      <td>J.R. Watkins Hand Cream, Lemon Cream</td>\n",
              "      <td>Personal Care,Skin Care,Hand Cream,Beauty,Body...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>AV1h6gSl-jtxr-f31p40</td>\n",
              "      <td>Ambi Complexion Cleansing Bar</td>\n",
              "      <td>Personal Care,Bath, Shower &amp; Soap,Featured Bra...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               productId  ...                                         categories\n",
              "0   AV13O1A8GV-KLJ3akUyj  ...  Movies, Music & Books,Music,R&b,Movies & TV,Mo...\n",
              "1   AV14LG0R-jtxr-f38QfS  ...  Food,Packaged Foods,Snacks,Crackers,Snacks, Co...\n",
              "3   AV16khLE-jtxr-f38VFn  ...  Personal Care,Medicine Cabinet,Lubricant/Sperm...\n",
              "30  AV1d76w7vKc47QAVhCqn  ...  Personal Care,Skin Care,Hand Cream,Beauty,Body...\n",
              "36  AV1h6gSl-jtxr-f31p40  ...  Personal Care,Bath, Shower & Soap,Featured Bra...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqGLNRxwmr5E"
      },
      "source": [
        "#### Preparing dataset for recommendation engine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIc91rHg3oh2"
      },
      "source": [
        "ratings = products[['userId','productId','rating']]"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "HRXi68RtTUfv",
        "outputId": "dae465b2-7285-4216-b5e1-fe9d8cda746d"
      },
      "source": [
        "ratings.head()"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>productId</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>joshua</td>\n",
              "      <td>AV13O1A8GV-KLJ3akUyj</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>dorothy w</td>\n",
              "      <td>AV14LG0R-jtxr-f38QfS</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>rebecca</td>\n",
              "      <td>AV16khLE-jtxr-f38VFn</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>walker557</td>\n",
              "      <td>AV16khLE-jtxr-f38VFn</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>samantha</td>\n",
              "      <td>AV16khLE-jtxr-f38VFn</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      userId             productId  rating\n",
              "0     joshua  AV13O1A8GV-KLJ3akUyj       5\n",
              "1  dorothy w  AV14LG0R-jtxr-f38QfS       5\n",
              "3    rebecca  AV16khLE-jtxr-f38VFn       1\n",
              "4  walker557  AV16khLE-jtxr-f38VFn       1\n",
              "5   samantha  AV16khLE-jtxr-f38VFn       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdSl-j5hU7wR"
      },
      "source": [
        "# Test and Train split of the dataset.\n",
        "train, test = train_test_split(ratings, test_size=0.30, random_state=31)"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0rYtncdVdq7",
        "outputId": "6aa2254c-20e1-41d3-a7c7-4770f0b40f5c"
      },
      "source": [
        "print(train.shape)\n",
        "print(test.shape)"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(19310, 3)\n",
            "(8276, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "SYYOwAuuVkTU",
        "outputId": "e8fd3f41-5464-46cb-a550-bfdeba5939ae"
      },
      "source": [
        "# Pivot the train ratings' dataset into matrix format in which columns are movies and the rows are user IDs.\n",
        "df_pivot_user = train.pivot(\n",
        "    index='userId',\n",
        "    columns='productId',\n",
        "    values='rating'\n",
        ").fillna(0)\n",
        "\n",
        "df_pivot_user.head(3)"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>productId</th>\n",
              "      <th>AV13O1A8GV-KLJ3akUyj</th>\n",
              "      <th>AV14LG0R-jtxr-f38QfS</th>\n",
              "      <th>AV16khLE-jtxr-f38VFn</th>\n",
              "      <th>AV1YGDqsGV-KLJ3adc-O</th>\n",
              "      <th>AV1YIch7GV-KLJ3addeG</th>\n",
              "      <th>AV1YlENIglJLPUi8IHsX</th>\n",
              "      <th>AV1YmBrdGV-KLJ3adewb</th>\n",
              "      <th>AV1YmDL9vKc47QAVgr7_</th>\n",
              "      <th>AV1Ymf_rglJLPUi8II2v</th>\n",
              "      <th>AV1Yn94nvKc47QAVgtst</th>\n",
              "      <th>AV1YnUMYglJLPUi8IJpK</th>\n",
              "      <th>AV1Ynb3bglJLPUi8IJxJ</th>\n",
              "      <th>AV1YneDPglJLPUi8IJyQ</th>\n",
              "      <th>AV1Yo6FPglJLPUi8IK3u</th>\n",
              "      <th>AV1YqAaMGV-KLJ3adiDj</th>\n",
              "      <th>AV1Ys0kTvKc47QAVgx1C</th>\n",
              "      <th>AV1YtGjdglJLPUi8IOfJ</th>\n",
              "      <th>AV1ZSp2uglJLPUi8IQFy</th>\n",
              "      <th>AV1ZT7GLglJLPUi8IQLI</th>\n",
              "      <th>AV1ZVIgy-jtxr-f31W9N</th>\n",
              "      <th>AV1d76w7vKc47QAVhCqn</th>\n",
              "      <th>AV1h6Gu0glJLPUi8IjA_</th>\n",
              "      <th>AV1h6gSl-jtxr-f31p40</th>\n",
              "      <th>AV1l8zRZvKc47QAVhnAv</th>\n",
              "      <th>AV2AvGnjGV-KLJ3alTQH</th>\n",
              "      <th>AV2Avn5dGV-KLJ3alTjq</th>\n",
              "      <th>AV2BOOWS-jtxr-f39GPS</th>\n",
              "      <th>AVpe-M4-ilAPnD_xSF1K</th>\n",
              "      <th>AVpe-MCY1cnluZ0-bCv_</th>\n",
              "      <th>AVpe-PJnLJeJML43ziaj</th>\n",
              "      <th>AVpe-YAL1cnluZ0-bHGh</th>\n",
              "      <th>AVpe-ltS1cnluZ0-bL8w</th>\n",
              "      <th>AVpe31o71cnluZ0-YrSD</th>\n",
              "      <th>AVpe38Uy1cnluZ0-YuJR</th>\n",
              "      <th>AVpe3_ikilAPnD_xPykq</th>\n",
              "      <th>AVpe4-GPLJeJML43xmuY</th>\n",
              "      <th>AVpe41TqilAPnD_xQH3d</th>\n",
              "      <th>AVpe4Bq81cnluZ0-YwTN</th>\n",
              "      <th>AVpe4hE0ilAPnD_xQABx</th>\n",
              "      <th>AVpe4hlXLJeJML43xbrB</th>\n",
              "      <th>...</th>\n",
              "      <th>AVpfi79RLJeJML43_Jo0</th>\n",
              "      <th>AVpfiRY_LJeJML43-8p9</th>\n",
              "      <th>AVpfiUrfLJeJML43-9nY</th>\n",
              "      <th>AVpfifml1cnluZ0-mjSb</th>\n",
              "      <th>AVpfjHuw1cnluZ0-mvrX</th>\n",
              "      <th>AVpfjauJLJeJML43_TKe</th>\n",
              "      <th>AVpfk4y7ilAPnD_xeTgd</th>\n",
              "      <th>AVpfkIiYilAPnD_xeEjr</th>\n",
              "      <th>AVpfkQkcLJeJML43_kEC</th>\n",
              "      <th>AVpfkak01cnluZ0-nJj6</th>\n",
              "      <th>AVpfl6baLJeJML43AEQq</th>\n",
              "      <th>AVpfl6sF1cnluZ0-nmwC</th>\n",
              "      <th>AVpfldDlLJeJML43_7s_</th>\n",
              "      <th>AVpfliCoilAPnD_xegIr</th>\n",
              "      <th>AVpfluP1ilAPnD_xejxO</th>\n",
              "      <th>AVpfm8yiLJeJML43AYyu</th>\n",
              "      <th>AVpfmVnVLJeJML43AMqC</th>\n",
              "      <th>AVpfmjXGLJeJML43AQ5_</th>\n",
              "      <th>AVpfnRuSilAPnD_xfB8l</th>\n",
              "      <th>AVpfnS4eLJeJML43AfZe</th>\n",
              "      <th>AVpfnUcwLJeJML43Af2U</th>\n",
              "      <th>AVpfnjBILJeJML43AkO3</th>\n",
              "      <th>AVpfoSS51cnluZ0-oVH9</th>\n",
              "      <th>AVpfov9TLJeJML43A7B0</th>\n",
              "      <th>AVpfozgyilAPnD_xfe0r</th>\n",
              "      <th>AVpfpM2yilAPnD_xfmDG</th>\n",
              "      <th>AVpfpoUCLJeJML43BLXv</th>\n",
              "      <th>AVpfqW4WilAPnD_xf7a_</th>\n",
              "      <th>AVpfr5cb1cnluZ0-pZFp</th>\n",
              "      <th>AVpfrFDZLJeJML43Bmv0</th>\n",
              "      <th>AVpfrTyiLJeJML43BrSI</th>\n",
              "      <th>AVpfrfHF1cnluZ0-pRai</th>\n",
              "      <th>AVpfrgjFLJeJML43BvCc</th>\n",
              "      <th>AVpfs0tUilAPnD_xgqN2</th>\n",
              "      <th>AVpfsQoeilAPnD_xgfx5</th>\n",
              "      <th>AVpfthSailAPnD_xg3ON</th>\n",
              "      <th>AVpftikC1cnluZ0-p31V</th>\n",
              "      <th>AVpftymALJeJML43CZ6y</th>\n",
              "      <th>AVpfv4TlilAPnD_xhjNS</th>\n",
              "      <th>AVpfvieo1cnluZ0-qdnu</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>userId</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>00dog3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>00sab00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>02dakota</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows  254 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "productId  AV13O1A8GV-KLJ3akUyj  ...  AVpfvieo1cnluZ0-qdnu\n",
              "userId                           ...                      \n",
              "00dog3                      0.0  ...                   0.0\n",
              "00sab00                     0.0  ...                   0.0\n",
              "02dakota                    0.0  ...                   0.0\n",
              "\n",
              "[3 rows x 254 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cA4SqZG38VuL"
      },
      "source": [
        "#### Creating dummy train & dummy test dataset\n",
        "These dataset will be used for prediction \n",
        "- Dummy train will be used later for prediction of the movies which has not been rated by the user. To ignore the movies rated by the user, we will mark it as 0 during prediction. The movies not rated by user is marked as 1 for prediction in dummy train dataset. \n",
        "\n",
        "- Dummy test will be used for evaluation. To evaluate, we will only make prediction on the movies rated by the user. So, this is marked as 1. This is just opposite of dummy_train."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zttrkghGExdD"
      },
      "source": [
        "# Copy the train dataset into dummy_train\n",
        "dummy_train = train.copy()"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3G4s9lvVExdD"
      },
      "source": [
        "# The movies not rated by user is marked as 1 for prediction. \n",
        "dummy_train['rating'] = dummy_train['rating'].apply(lambda x: 0 if x>=1 else 1)"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFSn3np7ExdD"
      },
      "source": [
        "# Convert the dummy train dataset into matrix format.\n",
        "dummy_train = dummy_train.pivot(\n",
        "    index='userId',\n",
        "    columns='productId',\n",
        "    values='rating'\n",
        ").fillna(1)"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Of3c1dioExdD",
        "outputId": "f2828a0d-22ec-4fd7-9604-a0f27573c94a"
      },
      "source": [
        "dummy_train.head()"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>productId</th>\n",
              "      <th>AV13O1A8GV-KLJ3akUyj</th>\n",
              "      <th>AV14LG0R-jtxr-f38QfS</th>\n",
              "      <th>AV16khLE-jtxr-f38VFn</th>\n",
              "      <th>AV1YGDqsGV-KLJ3adc-O</th>\n",
              "      <th>AV1YIch7GV-KLJ3addeG</th>\n",
              "      <th>AV1YlENIglJLPUi8IHsX</th>\n",
              "      <th>AV1YmBrdGV-KLJ3adewb</th>\n",
              "      <th>AV1YmDL9vKc47QAVgr7_</th>\n",
              "      <th>AV1Ymf_rglJLPUi8II2v</th>\n",
              "      <th>AV1Yn94nvKc47QAVgtst</th>\n",
              "      <th>AV1YnUMYglJLPUi8IJpK</th>\n",
              "      <th>AV1Ynb3bglJLPUi8IJxJ</th>\n",
              "      <th>AV1YneDPglJLPUi8IJyQ</th>\n",
              "      <th>AV1Yo6FPglJLPUi8IK3u</th>\n",
              "      <th>AV1YqAaMGV-KLJ3adiDj</th>\n",
              "      <th>AV1Ys0kTvKc47QAVgx1C</th>\n",
              "      <th>AV1YtGjdglJLPUi8IOfJ</th>\n",
              "      <th>AV1ZSp2uglJLPUi8IQFy</th>\n",
              "      <th>AV1ZT7GLglJLPUi8IQLI</th>\n",
              "      <th>AV1ZVIgy-jtxr-f31W9N</th>\n",
              "      <th>AV1d76w7vKc47QAVhCqn</th>\n",
              "      <th>AV1h6Gu0glJLPUi8IjA_</th>\n",
              "      <th>AV1h6gSl-jtxr-f31p40</th>\n",
              "      <th>AV1l8zRZvKc47QAVhnAv</th>\n",
              "      <th>AV2AvGnjGV-KLJ3alTQH</th>\n",
              "      <th>AV2Avn5dGV-KLJ3alTjq</th>\n",
              "      <th>AV2BOOWS-jtxr-f39GPS</th>\n",
              "      <th>AVpe-M4-ilAPnD_xSF1K</th>\n",
              "      <th>AVpe-MCY1cnluZ0-bCv_</th>\n",
              "      <th>AVpe-PJnLJeJML43ziaj</th>\n",
              "      <th>AVpe-YAL1cnluZ0-bHGh</th>\n",
              "      <th>AVpe-ltS1cnluZ0-bL8w</th>\n",
              "      <th>AVpe31o71cnluZ0-YrSD</th>\n",
              "      <th>AVpe38Uy1cnluZ0-YuJR</th>\n",
              "      <th>AVpe3_ikilAPnD_xPykq</th>\n",
              "      <th>AVpe4-GPLJeJML43xmuY</th>\n",
              "      <th>AVpe41TqilAPnD_xQH3d</th>\n",
              "      <th>AVpe4Bq81cnluZ0-YwTN</th>\n",
              "      <th>AVpe4hE0ilAPnD_xQABx</th>\n",
              "      <th>AVpe4hlXLJeJML43xbrB</th>\n",
              "      <th>...</th>\n",
              "      <th>AVpfi79RLJeJML43_Jo0</th>\n",
              "      <th>AVpfiRY_LJeJML43-8p9</th>\n",
              "      <th>AVpfiUrfLJeJML43-9nY</th>\n",
              "      <th>AVpfifml1cnluZ0-mjSb</th>\n",
              "      <th>AVpfjHuw1cnluZ0-mvrX</th>\n",
              "      <th>AVpfjauJLJeJML43_TKe</th>\n",
              "      <th>AVpfk4y7ilAPnD_xeTgd</th>\n",
              "      <th>AVpfkIiYilAPnD_xeEjr</th>\n",
              "      <th>AVpfkQkcLJeJML43_kEC</th>\n",
              "      <th>AVpfkak01cnluZ0-nJj6</th>\n",
              "      <th>AVpfl6baLJeJML43AEQq</th>\n",
              "      <th>AVpfl6sF1cnluZ0-nmwC</th>\n",
              "      <th>AVpfldDlLJeJML43_7s_</th>\n",
              "      <th>AVpfliCoilAPnD_xegIr</th>\n",
              "      <th>AVpfluP1ilAPnD_xejxO</th>\n",
              "      <th>AVpfm8yiLJeJML43AYyu</th>\n",
              "      <th>AVpfmVnVLJeJML43AMqC</th>\n",
              "      <th>AVpfmjXGLJeJML43AQ5_</th>\n",
              "      <th>AVpfnRuSilAPnD_xfB8l</th>\n",
              "      <th>AVpfnS4eLJeJML43AfZe</th>\n",
              "      <th>AVpfnUcwLJeJML43Af2U</th>\n",
              "      <th>AVpfnjBILJeJML43AkO3</th>\n",
              "      <th>AVpfoSS51cnluZ0-oVH9</th>\n",
              "      <th>AVpfov9TLJeJML43A7B0</th>\n",
              "      <th>AVpfozgyilAPnD_xfe0r</th>\n",
              "      <th>AVpfpM2yilAPnD_xfmDG</th>\n",
              "      <th>AVpfpoUCLJeJML43BLXv</th>\n",
              "      <th>AVpfqW4WilAPnD_xf7a_</th>\n",
              "      <th>AVpfr5cb1cnluZ0-pZFp</th>\n",
              "      <th>AVpfrFDZLJeJML43Bmv0</th>\n",
              "      <th>AVpfrTyiLJeJML43BrSI</th>\n",
              "      <th>AVpfrfHF1cnluZ0-pRai</th>\n",
              "      <th>AVpfrgjFLJeJML43BvCc</th>\n",
              "      <th>AVpfs0tUilAPnD_xgqN2</th>\n",
              "      <th>AVpfsQoeilAPnD_xgfx5</th>\n",
              "      <th>AVpfthSailAPnD_xg3ON</th>\n",
              "      <th>AVpftikC1cnluZ0-p31V</th>\n",
              "      <th>AVpftymALJeJML43CZ6y</th>\n",
              "      <th>AVpfv4TlilAPnD_xhjNS</th>\n",
              "      <th>AVpfvieo1cnluZ0-qdnu</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>userId</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>00dog3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>00sab00</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>02dakota</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>02deuce</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0325home</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  254 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "productId  AV13O1A8GV-KLJ3akUyj  ...  AVpfvieo1cnluZ0-qdnu\n",
              "userId                           ...                      \n",
              "00dog3                      1.0  ...                   1.0\n",
              "00sab00                     1.0  ...                   1.0\n",
              "02dakota                    1.0  ...                   1.0\n",
              "02deuce                     1.0  ...                   1.0\n",
              "0325home                    1.0  ...                   1.0\n",
              "\n",
              "[5 rows x 254 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXqgMNIjfQ2-"
      },
      "source": [
        "**Cosine Similarity**\n",
        "\n",
        "Cosine Similarity is a measurement that quantifies the similarity between two vectors [Which is Rating Vector in this case] \n",
        "\n",
        "**Adjusted Cosine**\n",
        "\n",
        "Adjusted cosine similarity is a modified version of vector-based similarity where we incorporate the fact that different users have different ratings schemes. In other words, some users might rate items highly in general, and others might give items lower ratings as a preference. To handle this nature from rating given by user , we subtract average ratings for each user from each user's rating for different movies.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCN3f1X0ExdE"
      },
      "source": [
        "#### Using Cosine Similarity on User-user"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AerlX5jdExdE",
        "outputId": "3d7de145-006c-49a6-dc71-89260a7c1533"
      },
      "source": [
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "\n",
        "# Creating the User Similarity Matrix using pairwise_distance function.\n",
        "user_correlation = 1 - pairwise_distances(df_pivot_user, metric='cosine')\n",
        "user_correlation[np.isnan(user_correlation)] = 0\n",
        "print(user_correlation)"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 1. 0. 1.]\n",
            " [0. 0. 0. ... 0. 1. 0.]\n",
            " [0. 0. 0. ... 1. 0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EA6M0wUExdF",
        "outputId": "625afeaf-7cb8-4bed-e71d-2e380d636aa9"
      },
      "source": [
        "user_correlation.shape"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17853, 17853)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZ-LgG6fDG8O"
      },
      "source": [
        "##### Prediction - User User"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uW4WjwV8DLp4"
      },
      "source": [
        "Doing the prediction for the users which are positively related with other users, and not the users which are negatively related as we are interested in the users which are more similar to the current users. So, ignoring the correlation for values less than 0. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZbkU7bwCdQ0",
        "outputId": "a17d812e-c432-470a-9d28-812a223b8005"
      },
      "source": [
        "user_correlation[user_correlation<0]=0\n",
        "user_correlation"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 1., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.],\n",
              "       [0., 0., 0., ..., 1., 0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uR_7OAnDOR4",
        "outputId": "17527209-8d83-4503-cd89-33a5aa472100"
      },
      "source": [
        "user_predicted_ratings = np.dot(user_correlation, df_pivot_user.fillna(0))\n",
        "user_predicted_ratings"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.98058068, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 3.00767062, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        3.53553391],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.57353933],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        3.53553391]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwQcKaG-DSNT",
        "outputId": "0af3b6db-8252-4c8e-9989-cdb22a324756"
      },
      "source": [
        "user_predicted_ratings.shape"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17853, 254)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "qzwO5Mu_DWkV",
        "outputId": "e49d3c2f-b2b1-4deb-afa2-22c92b990706"
      },
      "source": [
        "user_final_rating = np.multiply(user_predicted_ratings,dummy_train)\n",
        "user_final_rating.head(10)"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>productId</th>\n",
              "      <th>AV13O1A8GV-KLJ3akUyj</th>\n",
              "      <th>AV14LG0R-jtxr-f38QfS</th>\n",
              "      <th>AV16khLE-jtxr-f38VFn</th>\n",
              "      <th>AV1YGDqsGV-KLJ3adc-O</th>\n",
              "      <th>AV1YIch7GV-KLJ3addeG</th>\n",
              "      <th>AV1YlENIglJLPUi8IHsX</th>\n",
              "      <th>AV1YmBrdGV-KLJ3adewb</th>\n",
              "      <th>AV1YmDL9vKc47QAVgr7_</th>\n",
              "      <th>AV1Ymf_rglJLPUi8II2v</th>\n",
              "      <th>AV1Yn94nvKc47QAVgtst</th>\n",
              "      <th>AV1YnUMYglJLPUi8IJpK</th>\n",
              "      <th>AV1Ynb3bglJLPUi8IJxJ</th>\n",
              "      <th>AV1YneDPglJLPUi8IJyQ</th>\n",
              "      <th>AV1Yo6FPglJLPUi8IK3u</th>\n",
              "      <th>AV1YqAaMGV-KLJ3adiDj</th>\n",
              "      <th>AV1Ys0kTvKc47QAVgx1C</th>\n",
              "      <th>AV1YtGjdglJLPUi8IOfJ</th>\n",
              "      <th>AV1ZSp2uglJLPUi8IQFy</th>\n",
              "      <th>AV1ZT7GLglJLPUi8IQLI</th>\n",
              "      <th>AV1ZVIgy-jtxr-f31W9N</th>\n",
              "      <th>AV1d76w7vKc47QAVhCqn</th>\n",
              "      <th>AV1h6Gu0glJLPUi8IjA_</th>\n",
              "      <th>AV1h6gSl-jtxr-f31p40</th>\n",
              "      <th>AV1l8zRZvKc47QAVhnAv</th>\n",
              "      <th>AV2AvGnjGV-KLJ3alTQH</th>\n",
              "      <th>AV2Avn5dGV-KLJ3alTjq</th>\n",
              "      <th>AV2BOOWS-jtxr-f39GPS</th>\n",
              "      <th>AVpe-M4-ilAPnD_xSF1K</th>\n",
              "      <th>AVpe-MCY1cnluZ0-bCv_</th>\n",
              "      <th>AVpe-PJnLJeJML43ziaj</th>\n",
              "      <th>AVpe-YAL1cnluZ0-bHGh</th>\n",
              "      <th>AVpe-ltS1cnluZ0-bL8w</th>\n",
              "      <th>AVpe31o71cnluZ0-YrSD</th>\n",
              "      <th>AVpe38Uy1cnluZ0-YuJR</th>\n",
              "      <th>AVpe3_ikilAPnD_xPykq</th>\n",
              "      <th>AVpe4-GPLJeJML43xmuY</th>\n",
              "      <th>AVpe41TqilAPnD_xQH3d</th>\n",
              "      <th>AVpe4Bq81cnluZ0-YwTN</th>\n",
              "      <th>AVpe4hE0ilAPnD_xQABx</th>\n",
              "      <th>AVpe4hlXLJeJML43xbrB</th>\n",
              "      <th>...</th>\n",
              "      <th>AVpfi79RLJeJML43_Jo0</th>\n",
              "      <th>AVpfiRY_LJeJML43-8p9</th>\n",
              "      <th>AVpfiUrfLJeJML43-9nY</th>\n",
              "      <th>AVpfifml1cnluZ0-mjSb</th>\n",
              "      <th>AVpfjHuw1cnluZ0-mvrX</th>\n",
              "      <th>AVpfjauJLJeJML43_TKe</th>\n",
              "      <th>AVpfk4y7ilAPnD_xeTgd</th>\n",
              "      <th>AVpfkIiYilAPnD_xeEjr</th>\n",
              "      <th>AVpfkQkcLJeJML43_kEC</th>\n",
              "      <th>AVpfkak01cnluZ0-nJj6</th>\n",
              "      <th>AVpfl6baLJeJML43AEQq</th>\n",
              "      <th>AVpfl6sF1cnluZ0-nmwC</th>\n",
              "      <th>AVpfldDlLJeJML43_7s_</th>\n",
              "      <th>AVpfliCoilAPnD_xegIr</th>\n",
              "      <th>AVpfluP1ilAPnD_xejxO</th>\n",
              "      <th>AVpfm8yiLJeJML43AYyu</th>\n",
              "      <th>AVpfmVnVLJeJML43AMqC</th>\n",
              "      <th>AVpfmjXGLJeJML43AQ5_</th>\n",
              "      <th>AVpfnRuSilAPnD_xfB8l</th>\n",
              "      <th>AVpfnS4eLJeJML43AfZe</th>\n",
              "      <th>AVpfnUcwLJeJML43Af2U</th>\n",
              "      <th>AVpfnjBILJeJML43AkO3</th>\n",
              "      <th>AVpfoSS51cnluZ0-oVH9</th>\n",
              "      <th>AVpfov9TLJeJML43A7B0</th>\n",
              "      <th>AVpfozgyilAPnD_xfe0r</th>\n",
              "      <th>AVpfpM2yilAPnD_xfmDG</th>\n",
              "      <th>AVpfpoUCLJeJML43BLXv</th>\n",
              "      <th>AVpfqW4WilAPnD_xf7a_</th>\n",
              "      <th>AVpfr5cb1cnluZ0-pZFp</th>\n",
              "      <th>AVpfrFDZLJeJML43Bmv0</th>\n",
              "      <th>AVpfrTyiLJeJML43BrSI</th>\n",
              "      <th>AVpfrfHF1cnluZ0-pRai</th>\n",
              "      <th>AVpfrgjFLJeJML43BvCc</th>\n",
              "      <th>AVpfs0tUilAPnD_xgqN2</th>\n",
              "      <th>AVpfsQoeilAPnD_xgfx5</th>\n",
              "      <th>AVpfthSailAPnD_xg3ON</th>\n",
              "      <th>AVpftikC1cnluZ0-p31V</th>\n",
              "      <th>AVpftymALJeJML43CZ6y</th>\n",
              "      <th>AVpfv4TlilAPnD_xhjNS</th>\n",
              "      <th>AVpfvieo1cnluZ0-qdnu</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>userId</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>00dog3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.662975</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.662975</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.123475</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.332595</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>00sab00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.980581</td>\n",
              "      <td>5.655628</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.636634</td>\n",
              "      <td>1.290994</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.901263</td>\n",
              "      <td>0.901263</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.886751</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.386751</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.684304</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.332595</td>\n",
              "      <td>3.703774</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.610847</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.196152</td>\n",
              "      <td>5.277337</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.217161</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>2.684304</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.620712</td>\n",
              "      <td>1.164226</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>02dakota</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.007671</td>\n",
              "      <td>9.020571</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.121320</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.443389</td>\n",
              "      <td>0.901263</td>\n",
              "      <td>0.901263</td>\n",
              "      <td>3.535534</td>\n",
              "      <td>3.123475</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.123475</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.814773</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.415740</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>79.964290</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.105380</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.007885</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.612153</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.693375</td>\n",
              "      <td>4.503071</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.086067</td>\n",
              "      <td>6.035534</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>5.900543</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.952834</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.552301</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>02deuce</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.007671</td>\n",
              "      <td>9.020571</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.121320</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.443389</td>\n",
              "      <td>0.901263</td>\n",
              "      <td>0.901263</td>\n",
              "      <td>3.535534</td>\n",
              "      <td>3.123475</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.123475</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.814773</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.415740</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>79.964290</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.105380</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.007885</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.612153</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.693375</td>\n",
              "      <td>4.503071</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.086067</td>\n",
              "      <td>6.035534</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>5.900543</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.952834</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.552301</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0325home</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>12.040385</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.535534</td>\n",
              "      <td>3.535534</td>\n",
              "      <td>4.387725</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.502104</td>\n",
              "      <td>1.502104</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.980581</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.957819</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.886751</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>31.706242</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>2.097953</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.535534</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.097953</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.719346</td>\n",
              "      <td>3.914015</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.521452</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.717161</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.096570</td>\n",
              "      <td>3.535534</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.535534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>06stidriver</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>12.040385</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.535534</td>\n",
              "      <td>3.535534</td>\n",
              "      <td>4.387725</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.502104</td>\n",
              "      <td>1.502104</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.980581</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.957819</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.886751</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>31.706242</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>2.097953</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.535534</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.097953</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.719346</td>\n",
              "      <td>3.914015</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.521452</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.717161</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.096570</td>\n",
              "      <td>3.535534</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.535534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>08dallas</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.721326</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.201684</td>\n",
              "      <td>1.201684</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.535534</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.753806</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.128220</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>09mommy11</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.269405</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.617213</td>\n",
              "      <td>3.123475</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.886751</td>\n",
              "      <td>1.502104</td>\n",
              "      <td>1.502104</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.085144</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.547005</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30.365755</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.719346</td>\n",
              "      <td>1.273679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.610847</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.175971</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.620712</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.321192</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.11E+24</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>12.040385</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.535534</td>\n",
              "      <td>3.535534</td>\n",
              "      <td>4.387725</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.502104</td>\n",
              "      <td>1.502104</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.980581</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.957819</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.886751</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>31.706242</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>2.097953</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.535534</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.097953</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.719346</td>\n",
              "      <td>3.914015</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.521452</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.717161</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.096570</td>\n",
              "      <td>3.535534</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.535534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1085</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.236515</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.236068</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.979796</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.785242</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.628229</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>49.936467</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.572479</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.775984</td>\n",
              "      <td>5.329078</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.224745</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.033681</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.596174</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.573539</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows  254 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "productId    AV13O1A8GV-KLJ3akUyj  ...  AVpfvieo1cnluZ0-qdnu\n",
              "userId                             ...                      \n",
              "00dog3                        0.0  ...              0.000000\n",
              "00sab00                       0.0  ...              0.000000\n",
              "02dakota                      0.0  ...              0.000000\n",
              "02deuce                       0.0  ...              0.000000\n",
              "0325home                      0.0  ...              3.535534\n",
              "06stidriver                   0.0  ...              3.535534\n",
              "08dallas                      0.0  ...              0.000000\n",
              "09mommy11                     0.0  ...              0.000000\n",
              "1.11E+24                      0.0  ...              3.535534\n",
              "1085                          0.0  ...              0.573539\n",
              "\n",
              "[10 rows x 254 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4D8f7Uy6JGU"
      },
      "source": [
        "#### Item - Item Based"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6__ZeLbN6L4R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "a56a1cf8-bce8-49d7-b163-121a7333764e"
      },
      "source": [
        "df_pivot_item = train.pivot(\n",
        "    index='userId',\n",
        "    columns='productId',\n",
        "    values='rating'\n",
        ").T\n",
        "\n",
        "df_pivot_item.head()"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>userId</th>\n",
              "      <th>00dog3</th>\n",
              "      <th>00sab00</th>\n",
              "      <th>02dakota</th>\n",
              "      <th>02deuce</th>\n",
              "      <th>0325home</th>\n",
              "      <th>06stidriver</th>\n",
              "      <th>08dallas</th>\n",
              "      <th>09mommy11</th>\n",
              "      <th>1.11E+24</th>\n",
              "      <th>1085</th>\n",
              "      <th>1143mom</th>\n",
              "      <th>1234</th>\n",
              "      <th>1234561</th>\n",
              "      <th>1234567</th>\n",
              "      <th>123cat123</th>\n",
              "      <th>123charlie</th>\n",
              "      <th>123numbers</th>\n",
              "      <th>123soccermom</th>\n",
              "      <th>123too</th>\n",
              "      <th>127726</th>\n",
              "      <th>12cass12</th>\n",
              "      <th>12gage</th>\n",
              "      <th>132457</th>\n",
              "      <th>13dani</th>\n",
              "      <th>13ram</th>\n",
              "      <th>13thfaerie</th>\n",
              "      <th>1421nikki</th>\n",
              "      <th>143st</th>\n",
              "      <th>1515</th>\n",
              "      <th>15425shopper</th>\n",
              "      <th>1753</th>\n",
              "      <th>17roses</th>\n",
              "      <th>18612</th>\n",
              "      <th>1863philly</th>\n",
              "      <th>1943</th>\n",
              "      <th>1950rmm</th>\n",
              "      <th>1970</th>\n",
              "      <th>1992firebirdgirl</th>\n",
              "      <th>19bubba67</th>\n",
              "      <th>19granny</th>\n",
              "      <th>...</th>\n",
              "      <th>ziana</th>\n",
              "      <th>zibber23</th>\n",
              "      <th>zibby4</th>\n",
              "      <th>ziggy</th>\n",
              "      <th>zillafan</th>\n",
              "      <th>zillanator</th>\n",
              "      <th>zink</th>\n",
              "      <th>zinnian</th>\n",
              "      <th>zipperdoo</th>\n",
              "      <th>zippity</th>\n",
              "      <th>zippy</th>\n",
              "      <th>zitro</th>\n",
              "      <th>zittles</th>\n",
              "      <th>zkondrk</th>\n",
              "      <th>zman69</th>\n",
              "      <th>zmom</th>\n",
              "      <th>znxfyt</th>\n",
              "      <th>zod10</th>\n",
              "      <th>zoe1988</th>\n",
              "      <th>zoeellasca</th>\n",
              "      <th>zoey</th>\n",
              "      <th>zoeyny</th>\n",
              "      <th>zombiegirl22</th>\n",
              "      <th>zombiejess</th>\n",
              "      <th>zombiekiller</th>\n",
              "      <th>zombiekiller14</th>\n",
              "      <th>zone</th>\n",
              "      <th>zoney86</th>\n",
              "      <th>zooey_57</th>\n",
              "      <th>zoomin76</th>\n",
              "      <th>zotox</th>\n",
              "      <th>zout22389</th>\n",
              "      <th>zsarah</th>\n",
              "      <th>zsazsa</th>\n",
              "      <th>zulaa118</th>\n",
              "      <th>zwithanx</th>\n",
              "      <th>zxcsdfd</th>\n",
              "      <th>zxjki</th>\n",
              "      <th>zzdiane</th>\n",
              "      <th>zzz1127</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>productId</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>AV13O1A8GV-KLJ3akUyj</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AV14LG0R-jtxr-f38QfS</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AV16khLE-jtxr-f38VFn</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AV1YGDqsGV-KLJ3adc-O</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AV1YIch7GV-KLJ3addeG</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  17853 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "userId                00dog3  00sab00  02dakota  ...  zxjki  zzdiane  zzz1127\n",
              "productId                                        ...                         \n",
              "AV13O1A8GV-KLJ3akUyj     NaN      NaN       NaN  ...    NaN      NaN      NaN\n",
              "AV14LG0R-jtxr-f38QfS     NaN      NaN       NaN  ...    NaN      NaN      NaN\n",
              "AV16khLE-jtxr-f38VFn     NaN      NaN       NaN  ...    NaN      NaN      NaN\n",
              "AV1YGDqsGV-KLJ3adc-O     NaN      NaN       NaN  ...    NaN      NaN      NaN\n",
              "AV1YIch7GV-KLJ3addeG     NaN      NaN       NaN  ...    NaN      NaN      NaN\n",
              "\n",
              "[5 rows x 17853 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZpwDJKn6YN2"
      },
      "source": [
        "mean = np.nanmean(df_pivot_item, axis=1)\n",
        "df_subtracted = (df_pivot_item.T-mean).T"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WGDazaN6fgs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "90a7043d-031c-400d-9481-46a9a67ef3a3"
      },
      "source": [
        "df_subtracted.head()"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>userId</th>\n",
              "      <th>00dog3</th>\n",
              "      <th>00sab00</th>\n",
              "      <th>02dakota</th>\n",
              "      <th>02deuce</th>\n",
              "      <th>0325home</th>\n",
              "      <th>06stidriver</th>\n",
              "      <th>08dallas</th>\n",
              "      <th>09mommy11</th>\n",
              "      <th>1.11E+24</th>\n",
              "      <th>1085</th>\n",
              "      <th>1143mom</th>\n",
              "      <th>1234</th>\n",
              "      <th>1234561</th>\n",
              "      <th>1234567</th>\n",
              "      <th>123cat123</th>\n",
              "      <th>123charlie</th>\n",
              "      <th>123numbers</th>\n",
              "      <th>123soccermom</th>\n",
              "      <th>123too</th>\n",
              "      <th>127726</th>\n",
              "      <th>12cass12</th>\n",
              "      <th>12gage</th>\n",
              "      <th>132457</th>\n",
              "      <th>13dani</th>\n",
              "      <th>13ram</th>\n",
              "      <th>13thfaerie</th>\n",
              "      <th>1421nikki</th>\n",
              "      <th>143st</th>\n",
              "      <th>1515</th>\n",
              "      <th>15425shopper</th>\n",
              "      <th>1753</th>\n",
              "      <th>17roses</th>\n",
              "      <th>18612</th>\n",
              "      <th>1863philly</th>\n",
              "      <th>1943</th>\n",
              "      <th>1950rmm</th>\n",
              "      <th>1970</th>\n",
              "      <th>1992firebirdgirl</th>\n",
              "      <th>19bubba67</th>\n",
              "      <th>19granny</th>\n",
              "      <th>...</th>\n",
              "      <th>ziana</th>\n",
              "      <th>zibber23</th>\n",
              "      <th>zibby4</th>\n",
              "      <th>ziggy</th>\n",
              "      <th>zillafan</th>\n",
              "      <th>zillanator</th>\n",
              "      <th>zink</th>\n",
              "      <th>zinnian</th>\n",
              "      <th>zipperdoo</th>\n",
              "      <th>zippity</th>\n",
              "      <th>zippy</th>\n",
              "      <th>zitro</th>\n",
              "      <th>zittles</th>\n",
              "      <th>zkondrk</th>\n",
              "      <th>zman69</th>\n",
              "      <th>zmom</th>\n",
              "      <th>znxfyt</th>\n",
              "      <th>zod10</th>\n",
              "      <th>zoe1988</th>\n",
              "      <th>zoeellasca</th>\n",
              "      <th>zoey</th>\n",
              "      <th>zoeyny</th>\n",
              "      <th>zombiegirl22</th>\n",
              "      <th>zombiejess</th>\n",
              "      <th>zombiekiller</th>\n",
              "      <th>zombiekiller14</th>\n",
              "      <th>zone</th>\n",
              "      <th>zoney86</th>\n",
              "      <th>zooey_57</th>\n",
              "      <th>zoomin76</th>\n",
              "      <th>zotox</th>\n",
              "      <th>zout22389</th>\n",
              "      <th>zsarah</th>\n",
              "      <th>zsazsa</th>\n",
              "      <th>zulaa118</th>\n",
              "      <th>zwithanx</th>\n",
              "      <th>zxcsdfd</th>\n",
              "      <th>zxjki</th>\n",
              "      <th>zzdiane</th>\n",
              "      <th>zzz1127</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>productId</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>AV13O1A8GV-KLJ3akUyj</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AV14LG0R-jtxr-f38QfS</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AV16khLE-jtxr-f38VFn</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AV1YGDqsGV-KLJ3adc-O</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.151376</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AV1YIch7GV-KLJ3addeG</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  17853 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "userId                00dog3  00sab00  02dakota  ...  zxjki  zzdiane  zzz1127\n",
              "productId                                        ...                         \n",
              "AV13O1A8GV-KLJ3akUyj     NaN      NaN       NaN  ...    NaN      NaN      NaN\n",
              "AV14LG0R-jtxr-f38QfS     NaN      NaN       NaN  ...    NaN      NaN      NaN\n",
              "AV16khLE-jtxr-f38VFn     NaN      NaN       NaN  ...    NaN      NaN      NaN\n",
              "AV1YGDqsGV-KLJ3adc-O     NaN      NaN       NaN  ...    NaN      NaN      NaN\n",
              "AV1YIch7GV-KLJ3addeG     NaN      NaN       NaN  ...    NaN      NaN      NaN\n",
              "\n",
              "[5 rows x 17853 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Xoqby0anebw"
      },
      "source": [
        "##### Cosine Similarity on Item item based"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukjtZTUg6h8J"
      },
      "source": [
        "from sklearn.metrics.pairwise import pairwise_distances"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXdhiICH6mNP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56d07fee-4530-4388-8598-04510e39994e"
      },
      "source": [
        "item_correlation = 1 - pairwise_distances(df_subtracted.fillna(0), metric='cosine')\n",
        "item_correlation[np.isnan(item_correlation)] = 0\n",
        "print(item_correlation)"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 1. 0.]\n",
            " [0. 0. 0. ... 0. 0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgAgVFkX6qMW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6af45d71-fea0-4ea3-d43c-4d84dde3eff5"
      },
      "source": [
        "item_correlation[item_correlation<0]=0\n",
        "item_correlation"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oqAoA3Y6xG7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec41e643-7a3b-4cd1-c7c8-56610ab1a677"
      },
      "source": [
        "item_predicted_ratings = np.dot((df_pivot_item.fillna(0).T),item_correlation)\n",
        "item_predicted_ratings"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.00268827],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.00537654]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USBqztm962eH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7d3ec30-9d80-4e06-e9f5-6c4a9d517de8"
      },
      "source": [
        "item_predicted_ratings.shape"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17853, 254)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixfWProP66MW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b0d0a56-b36e-4ec8-ac45-8f86ff985e1a"
      },
      "source": [
        "dummy_train.shape"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17853, 254)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3NFHGEv68uI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "44b42353-1f3c-4f36-e423-358b6936ce15"
      },
      "source": [
        "item_final_rating = np.multiply(item_predicted_ratings,dummy_train)\n",
        "item_final_rating.head()"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>productId</th>\n",
              "      <th>AV13O1A8GV-KLJ3akUyj</th>\n",
              "      <th>AV14LG0R-jtxr-f38QfS</th>\n",
              "      <th>AV16khLE-jtxr-f38VFn</th>\n",
              "      <th>AV1YGDqsGV-KLJ3adc-O</th>\n",
              "      <th>AV1YIch7GV-KLJ3addeG</th>\n",
              "      <th>AV1YlENIglJLPUi8IHsX</th>\n",
              "      <th>AV1YmBrdGV-KLJ3adewb</th>\n",
              "      <th>AV1YmDL9vKc47QAVgr7_</th>\n",
              "      <th>AV1Ymf_rglJLPUi8II2v</th>\n",
              "      <th>AV1Yn94nvKc47QAVgtst</th>\n",
              "      <th>AV1YnUMYglJLPUi8IJpK</th>\n",
              "      <th>AV1Ynb3bglJLPUi8IJxJ</th>\n",
              "      <th>AV1YneDPglJLPUi8IJyQ</th>\n",
              "      <th>AV1Yo6FPglJLPUi8IK3u</th>\n",
              "      <th>AV1YqAaMGV-KLJ3adiDj</th>\n",
              "      <th>AV1Ys0kTvKc47QAVgx1C</th>\n",
              "      <th>AV1YtGjdglJLPUi8IOfJ</th>\n",
              "      <th>AV1ZSp2uglJLPUi8IQFy</th>\n",
              "      <th>AV1ZT7GLglJLPUi8IQLI</th>\n",
              "      <th>AV1ZVIgy-jtxr-f31W9N</th>\n",
              "      <th>AV1d76w7vKc47QAVhCqn</th>\n",
              "      <th>AV1h6Gu0glJLPUi8IjA_</th>\n",
              "      <th>AV1h6gSl-jtxr-f31p40</th>\n",
              "      <th>AV1l8zRZvKc47QAVhnAv</th>\n",
              "      <th>AV2AvGnjGV-KLJ3alTQH</th>\n",
              "      <th>AV2Avn5dGV-KLJ3alTjq</th>\n",
              "      <th>AV2BOOWS-jtxr-f39GPS</th>\n",
              "      <th>AVpe-M4-ilAPnD_xSF1K</th>\n",
              "      <th>AVpe-MCY1cnluZ0-bCv_</th>\n",
              "      <th>AVpe-PJnLJeJML43ziaj</th>\n",
              "      <th>AVpe-YAL1cnluZ0-bHGh</th>\n",
              "      <th>AVpe-ltS1cnluZ0-bL8w</th>\n",
              "      <th>AVpe31o71cnluZ0-YrSD</th>\n",
              "      <th>AVpe38Uy1cnluZ0-YuJR</th>\n",
              "      <th>AVpe3_ikilAPnD_xPykq</th>\n",
              "      <th>AVpe4-GPLJeJML43xmuY</th>\n",
              "      <th>AVpe41TqilAPnD_xQH3d</th>\n",
              "      <th>AVpe4Bq81cnluZ0-YwTN</th>\n",
              "      <th>AVpe4hE0ilAPnD_xQABx</th>\n",
              "      <th>AVpe4hlXLJeJML43xbrB</th>\n",
              "      <th>...</th>\n",
              "      <th>AVpfi79RLJeJML43_Jo0</th>\n",
              "      <th>AVpfiRY_LJeJML43-8p9</th>\n",
              "      <th>AVpfiUrfLJeJML43-9nY</th>\n",
              "      <th>AVpfifml1cnluZ0-mjSb</th>\n",
              "      <th>AVpfjHuw1cnluZ0-mvrX</th>\n",
              "      <th>AVpfjauJLJeJML43_TKe</th>\n",
              "      <th>AVpfk4y7ilAPnD_xeTgd</th>\n",
              "      <th>AVpfkIiYilAPnD_xeEjr</th>\n",
              "      <th>AVpfkQkcLJeJML43_kEC</th>\n",
              "      <th>AVpfkak01cnluZ0-nJj6</th>\n",
              "      <th>AVpfl6baLJeJML43AEQq</th>\n",
              "      <th>AVpfl6sF1cnluZ0-nmwC</th>\n",
              "      <th>AVpfldDlLJeJML43_7s_</th>\n",
              "      <th>AVpfliCoilAPnD_xegIr</th>\n",
              "      <th>AVpfluP1ilAPnD_xejxO</th>\n",
              "      <th>AVpfm8yiLJeJML43AYyu</th>\n",
              "      <th>AVpfmVnVLJeJML43AMqC</th>\n",
              "      <th>AVpfmjXGLJeJML43AQ5_</th>\n",
              "      <th>AVpfnRuSilAPnD_xfB8l</th>\n",
              "      <th>AVpfnS4eLJeJML43AfZe</th>\n",
              "      <th>AVpfnUcwLJeJML43Af2U</th>\n",
              "      <th>AVpfnjBILJeJML43AkO3</th>\n",
              "      <th>AVpfoSS51cnluZ0-oVH9</th>\n",
              "      <th>AVpfov9TLJeJML43A7B0</th>\n",
              "      <th>AVpfozgyilAPnD_xfe0r</th>\n",
              "      <th>AVpfpM2yilAPnD_xfmDG</th>\n",
              "      <th>AVpfpoUCLJeJML43BLXv</th>\n",
              "      <th>AVpfqW4WilAPnD_xf7a_</th>\n",
              "      <th>AVpfr5cb1cnluZ0-pZFp</th>\n",
              "      <th>AVpfrFDZLJeJML43Bmv0</th>\n",
              "      <th>AVpfrTyiLJeJML43BrSI</th>\n",
              "      <th>AVpfrfHF1cnluZ0-pRai</th>\n",
              "      <th>AVpfrgjFLJeJML43BvCc</th>\n",
              "      <th>AVpfs0tUilAPnD_xgqN2</th>\n",
              "      <th>AVpfsQoeilAPnD_xgfx5</th>\n",
              "      <th>AVpfthSailAPnD_xg3ON</th>\n",
              "      <th>AVpftikC1cnluZ0-p31V</th>\n",
              "      <th>AVpftymALJeJML43CZ6y</th>\n",
              "      <th>AVpfv4TlilAPnD_xhjNS</th>\n",
              "      <th>AVpfvieo1cnluZ0-qdnu</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>userId</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>00dog3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.019286</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.017398</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>00sab00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.004299</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001029</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>02dakota</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002323</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.014904</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.049048</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002067</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.046459</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.013286</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018547</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002243</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.014514</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000131</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>02deuce</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001858</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.011923</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.039239</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001653</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.037167</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.010628</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.014837</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001795</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.011611</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000104</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0325home</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000320</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002367</td>\n",
              "      <td>0.001919</td>\n",
              "      <td>0.005714</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00401</td>\n",
              "      <td>0.00282</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001783</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001695</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00693</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001530</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001369</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.006721</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  254 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "productId  AV13O1A8GV-KLJ3akUyj  ...  AVpfvieo1cnluZ0-qdnu\n",
              "userId                           ...                      \n",
              "00dog3                      0.0  ...              0.000000\n",
              "00sab00                     0.0  ...              0.000000\n",
              "02dakota                    0.0  ...              0.000000\n",
              "02deuce                     0.0  ...              0.000000\n",
              "0325home                    0.0  ...              0.006721\n",
              "\n",
              "[5 rows x 254 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTVi7x6voCi6"
      },
      "source": [
        "#### Compare User-user based to Item-Item based engine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtSX8CyIoBo3"
      },
      "source": [
        "#Comparing RMSE values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEkdljjr4bHc"
      },
      "source": [
        "### Recommendations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJdg9kRU4Ru5"
      },
      "source": [
        "### Task 7: Fine-Tuning the Recommendation System.. From 20 Recommendation to Top 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5DOBIaW3cJU"
      },
      "source": [
        "def getProductSentiment(model,X):\n",
        "  pred=model.predict(X)\n",
        "  prediction = model.predict_proba(X)\n",
        "  df_final = pd.DataFrame()\n",
        "  df_final['productId'] = products['productId']\n",
        "  df_final['name'] = products['name']\n",
        "  df_final['reviews_text'] = products['reviews_text']\n",
        "  df_pred_prob = pd.DataFrame(prediction, columns=['Negative','Positive'])\n",
        "  df_final['max_prob'] = df_pred_prob[['Negative','Positive']].max(axis=1)\n",
        "  df_final['max_prob_class'] = df_pred_prob.idxmax(axis=1)\n",
        "  df_final['Prediction'] = pred\n",
        "  return df_final"
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xzkf5OPUhMH2"
      },
      "source": [
        "def checkProductSentiment(productList,productsSentiments):\n",
        "  productPercent = {}\n",
        "  for id in productList:\n",
        "    filteredProduct = productsSentiments[productsSentiments['productId']==id]\n",
        "    percentPositive = filteredProduct['Prediction'].sum()/len(filteredProduct)\n",
        "    productPercent[id]=percentPositive\n",
        "  productPercentAsc =sorted(productPercent.items(), key=lambda x: x[1])\n",
        "  finalprodList = [i [0] for i in productPercentAsc[::-1][:5]]\n",
        "  return finalprodList"
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWBLkgqaMf6_"
      },
      "source": [
        "def getRecommendedProduct(username,productMapping,final_rating):\n",
        "  X_transformed_LR_scenario_1=tfidfconverter.transform(products['reviews_text'].tolist())\n",
        "  productsSentiments = getProductSentiment(logreg1, X_transformed_LR_scenario_1)\n",
        "  df_final = final_rating.loc[username].sort_values(ascending=False)[0:20]\n",
        "  df_final = pd.merge(df_final,productMapping,left_on='productId',right_on='productId',how = 'left')\n",
        "  productList = list(df_final['productId'])\n",
        "  final5 = checkProductSentiment(productList,productsSentiments)\n",
        "  df_final5 = df_final[df_final['productId'].isin(final5)]\n",
        "  print('Already Bought' + products[products['userId']==username]['name'].head())\n",
        "  print('All 20 recommendation')\n",
        "  print(df_final)\n",
        "  print('Top 5')\n",
        "  print(df_final5)\n",
        "  "
      ],
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzCIk1eT2z6-"
      },
      "source": [
        "### Task #6: Recommendation of Top 20 Products to a Specified User"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHlCnXaqcC1M",
        "outputId": "4df075d6-8376-402b-c9af-1e121186548a"
      },
      "source": [
        "# User - user based recommendation\n",
        "user_input = input(\"Enter your user name\")\n",
        "getRecommendedProduct(user_input,productMapping,user_final_rating)"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter your user name02dakota\n",
            "25656    Already BoughtGodzilla 3d Includes Digital Cop...\n",
            "Name: name, dtype: object\n",
            "All 20 recommendation\n",
            "               productId  ...                                         categories\n",
            "0   AVpfRTh1ilAPnD_xYic2  ...  Movies, Music & Books,Movies,Kids' & Family,Wa...\n",
            "1   AVpe41TqilAPnD_xQH3d  ...  Movies & TV Shows,Movies,Romance,Romantic Come...\n",
            "2   AVpf0eb2LJeJML43EVSt  ...  Movies, Music & Books,Ways To Shop Entertainme...\n",
            "3   AVpe59io1cnluZ0-ZgDU  ...  Movies, Music & Books,Movies,Comedy,Movies & T...\n",
            "4   AVpf2tw1ilAPnD_xjflC  ...  Movies & TV Shows,Instawatch Movies By VUDU,Sh...\n",
            "5   AVpf3VOfilAPnD_xjpun  ...  Household Essentials,Cleaning Supplies,Kitchen...\n",
            "6   AVpf0thK1cnluZ0-r8vR  ...  Movies, Music & Books,Movies,New Movie Release...\n",
            "7   AVpfJP1C1cnluZ0-e3Xy  ...  Household Chemicals,Household Cleaners,Bath & ...\n",
            "8   AVpfPnrU1cnluZ0-g9rL  ...  Movies, Music & Books,Movies,Sci-Fi & Fantasy,...\n",
            "9   AVpfM_ytilAPnD_xXIJb  ...  Food,Packaged Foods,Snacks,Chips & Pretzels,Fo...\n",
            "10  AVpe31o71cnluZ0-YrSD  ...  Movies, Music & Books,Movies,Comedy,Movies & T...\n",
            "11  AVpfD9xTLJeJML431ig2  ...  Movies, Music & Books,Movies,Comedy,Movies & T...\n",
            "12  AVpf5olc1cnluZ0-tPrO  ...  Food,Packaged Foods,Snacks,Chips & Pretzels,Fo...\n",
            "13  AVpfazX31cnluZ0-kbdl  ...  Personal Care,Hair Care,Hair Color And Bleachi...\n",
            "14  AVpfOIrkilAPnD_xXgDG  ...  Movies & TV Shows,Instawatch Movies By VUDU,In...\n",
            "15  AV1l8zRZvKc47QAVhnAv  ...  Personal Care,Skin Care,Anti-Aging,Beauty,Face...\n",
            "16  AVpf385g1cnluZ0-s0_t  ...  Food,Packaged Foods,Canned Foods,Canned Meals,...\n",
            "17  AV1YGDqsGV-KLJ3adc-O  ...  Household Essentials,Cleaning Supplies,Glass C...\n",
            "18  AVpfMpZ51cnluZ0-f_L9  ...  Food & Beverage,Cookies, Chips & Snacks,Cookie...\n",
            "19  AVpf63aJLJeJML43F__Q  ...  Personal Care,Makeup,Lipstick, Lip Gloss, & Li...\n",
            "\n",
            "[20 rows x 4 columns]\n",
            "Top 5\n",
            "              productId  ...                                         categories\n",
            "3  AVpe59io1cnluZ0-ZgDU  ...  Movies, Music & Books,Movies,Comedy,Movies & T...\n",
            "4  AVpf2tw1ilAPnD_xjflC  ...  Movies & TV Shows,Instawatch Movies By VUDU,Sh...\n",
            "6  AVpf0thK1cnluZ0-r8vR  ...  Movies, Music & Books,Movies,New Movie Release...\n",
            "7  AVpfJP1C1cnluZ0-e3Xy  ...  Household Chemicals,Household Cleaners,Bath & ...\n",
            "8  AVpfPnrU1cnluZ0-g9rL  ...  Movies, Music & Books,Movies,Sci-Fi & Fantasy,...\n",
            "\n",
            "[5 rows x 4 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCGceCNp7IQA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e8523a8-1711-4600-b6a5-c3e059d7ba82"
      },
      "source": [
        "# Item - Item based recommendation\n",
        "user_input = input(\"Enter your user name\")\n",
        "getRecommendedProduct(user_input,productMapping,item_final_rating)"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter your user name02dakota\n",
            "25656    Already BoughtGodzilla 3d Includes Digital Cop...\n",
            "Name: name, dtype: object\n",
            "All 20 recommendation\n",
            "               productId  ...                                         categories\n",
            "0   AVpf5olc1cnluZ0-tPrO  ...  Food,Packaged Foods,Snacks,Chips & Pretzels,Fo...\n",
            "1   AVpfE7puilAPnD_xUcCW  ...  Furniture,Bedroom Furniture,Nightstands,Home,H...\n",
            "2   AVpfBU2S1cnluZ0-cJsO  ...  Food,Packaged Foods,Snacks,Energy Bars,Health,...\n",
            "3   AVpfNc9cLJeJML434tza  ...  Home,Home Improvement,Light Bulbs,Electrical,A...\n",
            "4   AVpf0thK1cnluZ0-r8vR  ...  Movies, Music & Books,Movies,New Movie Release...\n",
            "5   AV1ZSp2uglJLPUi8IQFy  ...  Personal Care,Skin Care,Moisturizer,Beauty,Fac...\n",
            "6   AVpe41TqilAPnD_xQH3d  ...  Movies & TV Shows,Movies,Romance,Romantic Come...\n",
            "7   AVpf0pfrilAPnD_xi6s_  ...  Home,Home Decor,Home Accents,Artificial Flower...\n",
            "8   AVpfR5m0LJeJML436K3W  ...  Music on CD or Vinyl,Country Music on CD or Vi...\n",
            "9   AVpfnRuSilAPnD_xfB8l  ...  Personal Care,Bath, Shower & Soap,Body Wash & ...\n",
            "10  AVpe8gsILJeJML43y6Ed  ...  School & Office Supplies,Filing,Files,File Fol...\n",
            "11  AVpe8q4T1cnluZ0-afct  ...  Food,Packaged Foods,Candy,Soft Candy,Candy & G...\n",
            "12  AVpfAkX91cnluZ0-b4d8  ...  Personal Care,Makeup,Concealer & Foundation,Fo...\n",
            "13  AVpfD9xTLJeJML431ig2  ...  Movies, Music & Books,Movies,Comedy,Movies & T...\n",
            "14  AV1YqAaMGV-KLJ3adiDj  ...  Personal Care,Sun Care,Spray-on Sunscreen SPF ...\n",
            "15  AVpfpM2yilAPnD_xfmDG  ...  Food,Packaged Foods,Condiments, Dips, & Salad ...\n",
            "16  AVpe4hlXLJeJML43xbrB  ...  Food,Packaged Foods,Drinks,Juices,Fruit Flavor...\n",
            "17  AVpe6n2_LJeJML43yOgE  ...  Personal Care,Hair Care,Conditioner,Conditione...\n",
            "18  AVpfRTh1ilAPnD_xYic2  ...  Movies, Music & Books,Movies,Kids' & Family,Wa...\n",
            "19  AVpe59io1cnluZ0-ZgDU  ...  Movies, Music & Books,Movies,Comedy,Movies & T...\n",
            "\n",
            "[20 rows x 4 columns]\n",
            "Top 5\n",
            "               productId  ...                                         categories\n",
            "5   AV1ZSp2uglJLPUi8IQFy  ...  Personal Care,Skin Care,Moisturizer,Beauty,Fac...\n",
            "7   AVpf0pfrilAPnD_xi6s_  ...  Home,Home Decor,Home Accents,Artificial Flower...\n",
            "16  AVpe4hlXLJeJML43xbrB  ...  Food,Packaged Foods,Drinks,Juices,Fruit Flavor...\n",
            "17  AVpe6n2_LJeJML43yOgE  ...  Personal Care,Hair Care,Conditioner,Conditione...\n",
            "19  AVpe59io1cnluZ0-ZgDU  ...  Movies, Music & Books,Movies,Comedy,Movies & T...\n",
            "\n",
            "[5 rows x 4 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWKFCocuqQOP"
      },
      "source": [
        "### Prepare final item-item recommendation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9feDn04bL8dw"
      },
      "source": [
        "# Save dataframe to pickled pandas object\n",
        "# item_final_rating.to_pickle('/content/gdrive/MyDrive/Colab Data/item_final_rating')\n",
        "# # Load dataframe from pickled pandas object\n",
        "# df= pd.read_pickle(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}